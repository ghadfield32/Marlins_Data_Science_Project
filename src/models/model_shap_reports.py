import shapiq
from shapash import SmartExplainer
import pandas as pd
from explainerdashboard import RegressionExplainer, ExplainerDashboard
import dash_bootstrap_components as dbc  # optional, for nicer CSS themes

def launch_explainer_dashboard(
    model,
    X: pd.DataFrame,
    y,
    cats: list | dict | None = None,
    descriptions: dict | None = None,
    title: str = "Model Explainer",
    bootstrap: str = dbc.themes.FLATLY,
    **db_kwargs
):
    """
    Build and run an explainerdashboard for a regression model.
    - model: fitted XGBRegressor
    - X, y: numeric test set & labels
    - cats: list/dict of categorical column names
    - descriptions: mapping col -> human‑friendly text
    - title: dashboard title
    - bootstrap: dash_bootstrap_components theme
    - db_kwargs: other ExplainerDashboard flags (e.g. shap_interaction=False)
    """
    # 1) Create the RegressionExplainer
    explainer = RegressionExplainer(
        model,
        X,
        y,
        cats=cats or [],            # if you have categorical groups
        descriptions=descriptions or {},
        precision="float32"         # reduce memory footprint
    )
    # 2) Build the Dashboard
    db = ExplainerDashboard(
        explainer,
        title=title,
        bootstrap=bootstrap,
        shap_interaction=False,     # disable heavy tabs by default
        **db_kwargs
    )
    # 3) Run it (blocks)
    db.run(port=8050)


def generate_shapash_report(
    model,
    X: pd.DataFrame,
    y,
    features_dict: dict | None = None,
    preprocessing: object | None = None,
    report_path: str = "shapash_report.html"
):
    """
    Generate a Shapash HTML report from a numeric-only DataFrame.
    """
    # 1️⃣ Instantiate the explainer
    xpl = SmartExplainer(
        model=model,
        features_dict=features_dict or {c: c for c in X_num.columns},
        preprocessing=preprocessing
    )

    # 2️⃣ Predict using numeric inputs only
    y_pred = model.predict(X_num)

    # 3️⃣ Compile the explainability data
    xpl.compile(
        x=X_num,
        y_pred=y_pred,
        y_target=y,
        additional_data=None
    )

    # 4️⃣ Generate and save the standalone HTML report
    xpl.generate_report(
        output_file=report_path,
        title_story="Model Explainability Report",
        title_description="Auto-generated by Shapash",
        x_train=None,
        y_train=None,
        y_test=X_num,
        metrics=[]
    )

    return xpl


def compute_shapiq_interactions(
    model,
    X,
    sample_size: int = 100,
    max_order: int = 2
):
    """
    Use shapiq to compute Shapley Interaction values up to max_order
    for up to sample_size observations.

    Parameters:
    - model: trained ML model
    - X: pd.DataFrame of features
    - sample_size: how many rows to explain
    - max_order: maximum interaction order (e.g., 2 for pairwise)
    
    Returns:
    - interaction_values: shapiq InteractionValues object
    """
    # 1️⃣ Sample data for performance
    X_sample = X.sample(n=min(len(X), sample_size), random_state=42).to_numpy()
    # 2️⃣ Instantiate the explainer
    explainer = shapiq.TabularExplainer(
        model=model,
        data=X_sample,
        index="k-SII",   # or "SV" for standard Shapley values
        max_order=max_order
    )
    # 3️⃣ Explain the first sample
    interaction_values = explainer.explain(X_sample[0], budget=256)
    return interaction_values


if __name__ == "__main__":
    import pandas as pd
    from pathlib import Path
    from src.data.load_data import load_and_clean_data
    from src.features.feature_engineering import feature_engineer
    from src.features.preprocess import transform_preprocessor
    from src.models.gbm_utils import load_pipeline
    # from src.models.model_shap_reports import (
    #     generate_shapash_report,
    #     compute_shapiq_interactions
    # )
    from src.data.ColumnSchema import _ColumnSchema
    # singleton instance people can import as cols
    cols = _ColumnSchema()

    __all__ = ["cols"]
    print("ID columns:         ", cols.id())
    print("Ordinal columns:    ", cols.ordinal())
    print("Nominal columns:    ", cols.nominal())
    print("All categorical:    ", cols.categorical())
    print("Numerical columns:  ", cols.numerical())
    print("Model features:     ", cols.model_features())
    print("Target columns:     ", cols.target())
    print("All raw columns:    ", cols.all_raw())
    numericals = cols.numerical()
    
    # ─── A) Load model+preprocessor ───────────────────────────────────────────────
    model_path = Path("models/gbm_pipeline.joblib")
    if not model_path.exists():
        raise FileNotFoundError(f"{model_path} not found; run gbm.py first to train & save.")

    model, preprocessor = load_pipeline(str(model_path))

    # ─── B) Load & feature‑engineer raw data ───────────────────────────────────────
    raw_path = Path("data/Research Data Project/Research Data Project/exit_velo_project_data.csv")
    df_raw  = load_and_clean_data(str(raw_path))
    df_fe   = feature_engineer(df_raw)


    # After transform_preprocessor:
    X_arr, _ = transform_preprocessor(df_fe, preprocessor)
    numeric_cols = preprocessor.get_feature_names_out()
    X_numeric = pd.DataFrame(X_arr, columns=numeric_cols)
    
    # ─── C) Split off target & apply preprocessor ─────────────────────────────────
    # Here we explain on a hold‑out slice to demonstrate
    y_full = df_fe["exit_velo"]


    # ─── D) Generate a Shapash report ─────────────────────────────────────────────
    features_dict = {c: c.replace("_", " ").title() for c in X_full.columns}
    explainer = generate_shapash_report(
        model=model,
        X=X_numeric,      # or X_num if you rename the signature
        y=y_full,
        features_dict={c: c for c in X_numeric.columns},
        preprocessing=preprocessor,
        report_path="shapash_report.html"
    )

    print("✅ Shapash report written to shapash_report.html")

    # ─── E) Compute a quick Shapiq interaction for the first sample ─────────────────
    interactions = compute_shapiq_interactions(
        model=model,
        X=X_numeric,
        sample_size=50,
        max_order=2
    )
    print("✅ Shapiq interaction values for sample[0]:\n", interactions)

    # ─── F) (Optional) Show a quick summary of global SHAP importance ──────────────
    print("\nTop 5 features by mean absolute SHAP value:")
    shap_values = explainer.to_pandas().sort_values("mean_abs_shap", ascending=False)
    print(shap_values.head(5))
    
    
    import sys
        # ─── G) Launch an interactive explainerdashboard (optional) ───────────────
    if "--dashboard" in sys.argv:
        launch_explainer_dashboard(
            model=model,
            X=X_numeric,
            y=y_full,
            cats=cols.nominal(),         # or None
            descriptions={c: c for c in X_numeric.columns},
            shap_interaction=False,
            whatif=True,
            hide_wizard=True
        )
