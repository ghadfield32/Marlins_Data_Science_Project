**Explaining preprocessing techniques**

The user asks for detailed explanations of preprocessing steps in code like `numeric_linear`, `numeric_iterative`, `nominal_pipe`, and `dynamic pipelines`. This involves explaining null handling, numeric conversions, data normalization, and encoding techniques. I'll break down steps like handling missing data with imputers, scaling, and encoding variables. I'll go over the reasons for each choice, like why we use techniques like SimpleImputer or OneHotEncoder, how missingness is handled, and what assumptions are made. Additionally, I'll provide insight into each pipeline used in the process.


Thought for 5 seconds


Here’s a step‐by‐step walk-through of **every** piece of your `preprocess.py` and the reasoning behind it—why we do it, how it handles nulls, and how it fits different model types.

---

## 1  Numeric pipelines

You actually define two alternative numeric pipelines:

```python
numeric_linear = Pipeline([
    ('impute', SimpleImputer(strategy='median', add_indicator=True)),
    ('scale', StandardScaler()),
])
numeric_iterative = Pipeline([
    ('impute', IterativeImputer(random_state=0, add_indicator=True)),
    ('scale', StandardScaler()),
])
```

### 1.1  Imputation

* **`SimpleImputer(strategy='median')`**

  * **Why median?** It’s robust to outliers (unlike the mean) and preserves the center of the distribution.
* **`IterativeImputer`**

  * **Why iterative?** It uses other features to predict missing values via, e.g., BayesianRidge, giving more informed imputations when variables are correlated.
* **`add_indicator=True`**

  * **Why add an indicator column?** Knowing *where* data was missing can itself be predictive (e.g. if high-value players are more likely to have full stat lines).

### 1.2  Scaling

* **`StandardScaler()`**

  * Centers to mean = 0 and scales to unit variance.
  * **Why?**

    * For **linear** models, ensures coefficients are on comparable scales.
    * Even for tree models, standardized inputs can help optimization.

---

## 2  Nominal‐categorical pipeline

```python
nominal_pipe = Pipeline([
    ('impute', SimpleImputer(strategy='constant', fill_value='MISSING')),
    ('encode', OneHotEncoder(drop='first', handle_unknown='ignore')),
])
```

### 2.1  Categorical imputation

* **`strategy='constant', fill_value='MISSING'`**

  * Treats missing categories as their own level “MISSING.”
  * **Why?** Preserves missingness rather than discarding or arbitrarily assigning the most frequent category.

### 2.2  One‐hot encoding

* **`drop='first'`**

  * Avoids the “dummy‐variable trap” (multicollinearity in linear models) by dropping one level.
* **`handle_unknown='ignore'`**

  * At transform time, new unseen levels become all-zero vectors rather than erroring.

---

## 3  Ordinal pipeline

Inside `fit_preprocessor` we build:

```python
ordinal_pipe = Pipeline([
    ('impute', SimpleImputer(strategy='constant', fill_value='MISSING')),
    ('encode', OrdinalEncoder(categories=ordinal_categories, dtype='int32')),
])
```

### 3.1  Why an ordinal pipeline?

* Certain categorical features have a natural order—e.g. competition levels (`AA` < `AAA` < `MLB`), spray‐angle bins from pull to oppo.
* We **impute** missing as “MISSING” so the encoder sees that level.
* We **pass in** each feature’s list of categories (in correct order), so the encoder maps them to successive integers.

---

## 4  `fit_preprocessor`: end-to-end flow

```python
def fit_preprocessor(df, model_type='linear', debug=False):
    cols = _ColumnSchema()
    TARGET_COL = cols.target()
```

### 4.1  1) Drop bunts

```python
df = df[df["hit_type"].str.upper() != "BUNT"].copy()
```

* **Why?** Bunts have little to no “exit velocity” signal—drop them entirely.

### 4.2  2) Drop rows missing the target

```python
df_clean = df.dropna(subset=[TARGET_COL]).copy()
```

* **Why?** You can’t train on rows where `exit_velo` is missing. Never impute your **y**.

### 4.3  3) Force numeric types

```python
FEATURE_NUMERIC = [c for c in cols.numerical() if c != TARGET_COL]
df_clean[FEATURE_NUMERIC] = df_clean[FEATURE_NUMERIC].apply(
    pd.to_numeric, errors='coerce'
)
```

* Turns stray strings into NaNs (so they’ll be caught by your imputer).

### 4.4  4) Center age

```python
df_clean['age_centered'] = df_clean['age'] - df_clean['age'].median()
```

* **Why centering?**

  * Reduces correlation between the raw age and any interaction terms.
  * Makes your model’s intercept interpretable at the “median age.”

### 4.5  5) Map competition level

```python
df_clean['level_idx'] = df_clean['level_abbr'].map({'AA': 0, 'AAA': 1, 'MLB': 2})
```

* Creates a simple numeric proxy for “level of play.”

### 4.6  6) Auto-detect ordinal categories

```python
ORDINAL_CAT_COLS = cols.ordinal()
for col in ORDINAL_CAT_COLS:
    X[col] = X[col].map(lambda v: str(v) if pd.notna(v) else np.nan)

ordinal_categories = []
for col in ORDINAL_CAT_COLS:
    vals = X[col].dropna().unique().tolist()
    vals.append('MISSING')
    ordinal_categories.append(vals)
```

* Converts everything to strings (so pandas won’t mix dtypes).
* Gathers each column’s unique levels, *then* adds `"MISSING"` so your encoder knows to handle nulls.

### 4.7  7) Assemble the `ColumnTransformer`

```python
transformers = [
    ('num', numeric_linear if model_type=='linear' else 'passthrough', FEATURE_NUMERIC),
    ('ord', ordinal_pipe, ORDINAL_CAT_COLS),
    ('nom', nominal_pipe, cols.nominal()),
]
preproc = ColumnTransformer(transformers, remainder='drop')
```

* **Numeric** → your linear‐model pipeline (or passthrough for tree models).
* **Ordinal** → the ordinal pipeline above.
* **Nominal** → one-hot pipeline.
* **Drop everything else**.

If you send `debug=True`, you’ll see exactly which categories were detected for each ordinal column.

---

## 5  `transform_preprocessor`

Follows the same steps **except**:

* You don’t drop bunts or re-fit; you simply:

  1. Drop rows missing **y**
  2. Recompute age centering (using the *same* median!)
  3. Remap `level_abbr` → `level_idx`
  4. Normalize ordinals to strings
  5. Call `transformer.transform(X)`

---

## 6  Missingness summary

```python
def summarize_categorical_missingness(df):
    # For each cat column, reports:
    #    original_null_count, pct
    #    imputed_missing_count, pct
```

* Lets you inspect—*before* fitting—how many nulls you have in each categorical column, and what fraction will end up as `"MISSING"`.
* Helps diagnose: e.g. if 50% of your data is missing one feature, maybe you need a different strategy.

---

### Why all of this matters

1. **Transparent handling of nulls**

   * Numeric: you impute intelligently *and* keep track of where you imputed.
   * Categorical: you elevate missingness to its own level rather than silently dropping or filling with the most common.

2. **Right encoding for the right model**

   * Linear models **need** scaled, non‐collinear inputs.
   * Tree‐based models often don’t care about scaling, so you can switch to a simpler passthrough.

3. **Reproducibility & debugability**

   * The debug flag prints exactly what categories were detected.
   * Your summary function quantifies missingness up front.

4. **Semantic feature creation**

   * Centering age gives interpretable coefficients.
   * Mapping levels to integers reflects the ordinal relationship.

---

With this you have both **the how** (code) and **the why** (the logic behind each choice), so you can justify every preprocessing step in your write-up or next code review.
