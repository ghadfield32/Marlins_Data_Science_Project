{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exit-velo-proj/\n",
    "├─ src/\n",
    "│  ├─ data/\n",
    "│  │   └─ load_data.py        # load_raw()\n",
    "│  ├─ features/\n",
    "│  │   └─ preprocess.py       # preprocess(df) → df_clean\n",
    "│  ├─ models/\n",
    "│  │   ├─ baseline.py         # fit_mixed(), extract_empirical_bayes()\n",
    "│  │   └─ hierarchical.py     # fit_bayesian_hierarchical(), posterior_predictive_draws()\n",
    "│  └─ utils/\n",
    "│      └─ helpers.py          # compute_league_prior(), estimate_noise_variance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/data/load_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/data/load_data.py\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_raw(path='data/Research Data Project/Research Data Project/exit_velo_project_data.csv'):\n",
    "    \"\"\"\n",
    "    Load raw exit velocity data from the data directory.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Raw exit velocity data\n",
    "    \"\"\"\n",
    "    # This is a placeholder - in a real implementation, you would load actual data\n",
    "    # For example: df = pd.read_csv('data/raw/exit_velo.csv')\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    return df \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = 'data/Research Data Project/Research Data Project/exit_velo_project_data.csv'\n",
    "    df = load_raw(path)\n",
    "    print(df.head())\n",
    "    print(df.columns)\n",
    "\n",
    "    # --- inspect nulls in the raw data ---\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    if null_counts.empty:\n",
    "        print(\"✅  No missing values in raw data.\")\n",
    "    else:\n",
    "        print(\"=== Raw data null counts ===\")\n",
    "        for col, cnt in null_counts.items():\n",
    "            print(f\" • {col!r}: {cnt} missing\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/features/feature_engineering.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/features/feature_engineering.py\n",
    "\"\"\"Feature engineering utilities for the exit‑velo project.\n",
    "\n",
    "All helpers are pure functions that take a pandas DataFrame and return a *copy*\n",
    "with additional engineered columns so we avoid side effects.\n",
    "\n",
    "Example\n",
    "-------\n",
    ">>> from src.data.load_data import load_raw\n",
    ">>> from src.features.feature_engineering import feature_engineer\n",
    ">>> df = load_raw()\n",
    ">>> df_fe = feature_engineer(df)\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "###############################################################################\n",
    "# Helper functions\n",
    "###############################################################################\n",
    "\n",
    "def _rolling_stat(\n",
    "    df: pd.DataFrame,\n",
    "    group_cols: list[str],\n",
    "    target: str,\n",
    "    stat: str = \"mean\",\n",
    "    window: int = 50,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Group‑wise rolling statistic.  Sorted by season order of appearance.\n",
    "\n",
    "    The function first sorts by the index order (assumed chronological inside each\n",
    "    group) then applies a rolling window with *min_periods=10* so early samples\n",
    "    are not overly noisy.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        df.sort_values(group_cols)\n",
    "        .groupby(group_cols)[target]\n",
    "        .rolling(window, min_periods=10)\n",
    "        .agg(stat)\n",
    "        .reset_index(level=group_cols, drop=True)\n",
    "    )\n",
    "\n",
    "###############################################################################\n",
    "# Public API\n",
    "###############################################################################\n",
    "\n",
    "def feature_engineer(df: pd.DataFrame, copy: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Return a DataFrame enriched with engineered features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df   : raw data as returned by ``load_raw``\n",
    "    copy : if *True* (default) operate on a copy so the original is untouched.\n",
    "    \"\"\"\n",
    "\n",
    "    if copy:\n",
    "        df = df.copy()\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    # 1. Basic type harmonisation & canonical casing\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    str_cols = df.select_dtypes(include=['object', 'string']).columns\n",
    "    df[str_cols] = df[str_cols].apply(lambda col: col.str.upper())\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    # 2. Age engineering (dynamic quantile bins)\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    df[\"age_sq\"] = df[\"age\"] ** 2  # capture non‑linear aging curve\n",
    "    n_age_bins = 4\n",
    "    df[\"age_bin\"] = pd.qcut(df[\"age\"], q=n_age_bins, duplicates='drop')\n",
    "    \n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    # 3. Height normalisation relative to MLB average (~74 inches)\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    df[\"height_diff\"] = df[\"batter_height\"] - 74\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    # 4. Launch / spray angle buckets (dynamic quantile bins) & barrel indicator\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    # Dynamic launch-angle bins\n",
    "    n_la_bins = 5\n",
    "    df[\"la_bin\"] = pd.qcut(df[\"launch_angle\"], q=n_la_bins, duplicates='drop')\n",
    "\n",
    "    # Dynamic spray-angle bins\n",
    "    n_spray_bins = 3\n",
    "    df[\"spray_bin\"] = pd.qcut(df[\"spray_angle\"], q=n_spray_bins, duplicates='drop')\n",
    "\n",
    "    # Statcast barrel proxy: EV >= 98 & 26° > LA >= 8°\n",
    "    df[\"is_barrel\"] = (\n",
    "        (df[\"exit_velo\"] >= 98) & (df[\"launch_angle\"] >= 8) & (df[\"launch_angle\"] < 26)\n",
    "    ).astype(\"category\")\n",
    "\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    # 6. Handedness & matchup indicators\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    df[\"same_hand\"] = (df[\"batter_hand\"] == df[\"pitcher_hand\"])\n",
    "    df[\"hand_match\"] = df[\"batter_hand\"] + \"_VS_\" + df[\"pitcher_hand\"]\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    # 7. Pitch‑type interactions\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    df[\"pitch_hand_match\"] = df[\"pitch_group\"] + \"_\" + df[\"hand_match\"]\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    # 8. Player‑level historical stats (rolling EV mean & SD)\n",
    "    #    These capture each hitter’s *latent* ability and shrink early samples\n",
    "    #    via wider rolling windows.\n",
    "    # ────────────────────────────────────────────────────────────────────────\n",
    "    df[\"player_ev_mean50\"] = _rolling_stat(df, [\"batter_id\"], \"exit_velo\", \"mean\", 50)\n",
    "    df[\"player_ev_std50\"] = _rolling_stat(df, [\"batter_id\"], \"exit_velo\", \"std\", 50)\n",
    "    # ✱ NEW: safe assignment, no inplace chain ✱\n",
    "    ev_mean_global = df[\"exit_velo\"].mean()\n",
    "    ev_std_global  = df[\"exit_velo\"].std()\n",
    "    df[\"player_ev_mean50\"] = df[\"player_ev_mean50\"].fillna(ev_mean_global)\n",
    "    df[\"player_ev_std50\"]  = df[\"player_ev_std50\"].fillna(ev_std_global)\n",
    "\n",
    "    # 9a. Hard‑hit & barrel‑adjacent flags\n",
    "    df[\"hard_hit\"] = (df[\"exit_velo\"] >= 95).astype(\"category\")\n",
    "    df[\"near_barrel\"] = (\n",
    "        (df[\"exit_velo\"].between(95, 98)) &\n",
    "        (df[\"launch_angle\"].between(5, 30))\n",
    "    ).astype(\"category\")\n",
    "\n",
    "    # 9b. EV × LA and distance proxy\n",
    "    df[\"ev_la_product\"] = df[\"exit_velo\"] * (df[\"launch_angle\"] + 90)\n",
    "    df[\"est_distance\"] = df[\"exit_velo\"] * df[\"hangtime\"]\n",
    "    #  Variance‑stabilised EV×LA\n",
    "    df[\"ev_la_sqrt\"] = np.sqrt(df[\"ev_la_product\"].clip(lower=0))\n",
    "\n",
    "    # 10. Pitcher rolling stats\n",
    "    df[\"pitcher_ev_mean50\"] = _rolling_stat(df, [\"pitcher_id\"], \"exit_velo\", \"mean\", 50)\n",
    "    df[\"pitcher_ev_mean50\"].fillna(df[\"exit_velo\"].mean(), inplace=True)\n",
    "\n",
    "    # 11. Outcome encoding – simple value mapping for power/speed signal.\n",
    "    _OUTCOME_W = {\n",
    "        \"out\": 0,\n",
    "        \"single\": 1,\n",
    "        \"double\": 2,\n",
    "        \"triple\": 3,\n",
    "        \"home run\": 4,\n",
    "    }\n",
    "    df[\"outcome_val\"] = df[\"outcome\"].str.lower().map(_OUTCOME_W)\n",
    "\n",
    "    return df\n",
    "\n",
    "###############################################################################\n",
    "# CLI entry‑point (quick smoke test)\n",
    "###############################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    from src.data.load_data import load_raw\n",
    "\n",
    "    raw_path = \"data/Research Data Project/Research Data Project/exit_velo_project_data.csv\"\n",
    "    df = load_raw(raw_path)\n",
    "    print(df.head())\n",
    "    print(df.columns)\n",
    "\n",
    "    # --- inspect nulls in the raw data ---\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    if null_counts.empty:\n",
    "        print(\"✅  No missing values in raw data.\")\n",
    "    else:\n",
    "        print(\"=== Raw data null counts ===\")\n",
    "        for col, cnt in null_counts.items():\n",
    "            print(f\" • {col!r}: {cnt} missing\")\n",
    "    df_fe = feature_engineer(df)\n",
    "\n",
    "    print(\"Raw →\", df.shape, \"//  Feature‑engineered →\", df_fe.shape)\n",
    "    print(df_fe.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ColumnSchema: separates raw and engineered columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/data/ColumnSchema.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/data/ColumnSchema.py\n",
    "\"\"\" \n",
    "Column schema helper for exit‑velo project.\n",
    "\n",
    "Centralises every raw and engineered column name in one place and exposes\n",
    " type‑safe accessors so downstream code never hard‑codes strings.\n",
    "\n",
    "Usage\n",
    "-----\n",
    ">>> from src.features.columns import cols\n",
    ">>> num_cols = cols.numerical()\n",
    ">>> ord_cols = cols.ordinal()\n",
    ">>> all_for_model = cols.model_features()\n",
    "\"\"\"\n",
    "\n",
    "from functools import lru_cache\n",
    "from typing import List, Dict\n",
    "import json\n",
    "\n",
    "class _ColumnSchema:\n",
    "    \"\"\"Container for canonical column lists.\n",
    "\n",
    "    Keeping everything behind methods avoids accidental mutation and lets\n",
    "    IDEs offer autocompletion (because the return type is always `List[str]`).\n",
    "    \"\"\"\n",
    "\n",
    "    _ID_COLS: List[str] = [\n",
    "        \"season\", \"batter_id\", \"pitcher_id\",\n",
    "    ]\n",
    "\n",
    "    _ORDINAL_CAT_COLS: List[str] = [\n",
    "        \"level_abbr\",   # AA < AAA < MLB\n",
    "        \"age_bin\",      # 4 quantile bins of age\n",
    "        \"la_bin\",       # 5 quantile bins of launch angle\n",
    "        \"spray_bin\",    # 3 quantile bins of spray angle\n",
    "        \"outcome_val\",  # 0–4 mapping of out→HR\n",
    "    ]\n",
    "\n",
    "    _NOMINAL_CAT_COLS: List[str] = [\n",
    "        \"hit_type\",\n",
    "        \"outcome\",\n",
    "        \"pitch_group\",\n",
    "        \"batter_hand\",\n",
    "        \"pitcher_hand\",\n",
    "        \"hand_match\",\n",
    "        \"pitch_hand_match\",\n",
    "        \"same_hand\",\n",
    "        \"is_barrel\",\n",
    "        \"hard_hit\",\n",
    "        \"near_barrel\",\n",
    "    ]\n",
    "\n",
    "    _NUMERICAL_COLS: List[str] = [\n",
    "        # raw inputs\n",
    "        \"exit_velo\",\n",
    "        \"launch_angle\",\n",
    "        \"spray_angle\",\n",
    "        \"hangtime\",\n",
    "        # engineered continuous\n",
    "        \"ev_la_product\",\n",
    "        \"ev_la_sqrt\",\n",
    "        \"est_distance\",\n",
    "        \"player_ev_mean50\",\n",
    "        \"player_ev_std50\",\n",
    "        \"pitcher_ev_mean50\",\n",
    "    ]\n",
    "\n",
    "    _TARGET_COL: str = \"exit_velo\"\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────────────\n",
    "    # Public helpers\n",
    "    # ────────────────────────────────────────────────────────────────────\n",
    "    def id(self) -> List[str]:\n",
    "        return self._ID_COLS.copy()\n",
    "\n",
    "    def ordinal(self) -> List[str]:\n",
    "        return self._ORDINAL_CAT_COLS.copy()\n",
    "\n",
    "    def nominal(self) -> List[str]:\n",
    "        return self._NOMINAL_CAT_COLS.copy()\n",
    "\n",
    "    def categorical(self) -> List[str]:\n",
    "        \"\"\"All cat cols (ordinal + nominal).\"\"\"\n",
    "        return self._ORDINAL_CAT_COLS + self._NOMINAL_CAT_COLS\n",
    "\n",
    "    def numerical(self) -> List[str]:\n",
    "        return self._NUMERICAL_COLS.copy()\n",
    "\n",
    "\n",
    "    def target(self) -> str:\n",
    "        return self._TARGET_COL\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    @lru_cache(maxsize=1)\n",
    "    def model_features(self) -> List[str]:\n",
    "        \"\"\"Columns fed into the ML pipeline *after* preprocess.\n",
    "\n",
    "        Excludes the target but includes derived cols.\n",
    "        \"\"\"\n",
    "        phys_minus_target = [\n",
    "            c for c in self._NUMERICAL_COLS if c != self._TARGET_COL\n",
    "        ]\n",
    "\n",
    "        return (\n",
    "            phys_minus_target\n",
    "            + self._NOMINAL_CAT_COLS\n",
    "            + self._ORDINAL_CAT_COLS  # some algos want raw string order\n",
    "        )\n",
    "\n",
    "    def all_raw(self) -> List[str]:\n",
    "        \"\"\"Returns every column expected in raw input CSV (incl. engineered).\"\"\"\n",
    "        return (\n",
    "            self._ID_COLS\n",
    "            + self._ORDINAL_CAT_COLS\n",
    "            + self._NOMINAL_CAT_COLS\n",
    "            + self._NUMERICAL_COLS\n",
    "        )\n",
    "\n",
    "    def as_dict(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Dictionary form – handy for YAML/JSON dumps.\"\"\"\n",
    "        return {\n",
    "            \"id\": self.id(),\n",
    "            \"ordinal\": self.ordinal(),\n",
    "            \"nominal\": self.nominal(),\n",
    "            \"numerical\": self.numerical(),\n",
    "            \"target\": [self.target()],\n",
    "        }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # singleton instance people can import as `cols`\n",
    "    cols = _ColumnSchema()\n",
    "\n",
    "    __all__ = [\"cols\"]\n",
    "    print(\"ID columns:         \", cols.id())\n",
    "    print(\"Ordinal columns:    \", cols.ordinal())\n",
    "    print(\"Nominal columns:    \", cols.nominal())\n",
    "    print(\"All categorical:    \", cols.categorical())\n",
    "    print(\"Numerical columns:  \", cols.numerical())\n",
    "    print(\"Target column:      \", cols.target())\n",
    "    print(\"Model features:     \", cols.model_features())\n",
    "    print(\"All raw columns:    \", cols.all_raw())\n",
    "    print(\"\\nAs dict (JSON):\")\n",
    "    print(json.dumps(cols.as_dict(), indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/features/eda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/features/eda.py\n",
    "\n",
    "import pandas as pd  # type: ignore\n",
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "import numpy as np  # type: ignore\n",
    "from src.data.ColumnSchema import _ColumnSchema\n",
    "\n",
    "# Optional imports with fallbacks for advanced statistics\n",
    "try:\n",
    "    import scipy.stats as stats  # type: ignore\n",
    "    from statsmodels.nonparametric.smoothers_lowess import (\n",
    "        lowess  # type: ignore\n",
    "    )\n",
    "    from statsmodels.stats.stattools import (\n",
    "        durbin_watson  # type: ignore\n",
    "    )\n",
    "    _HAS_STATS_LIBS = True\n",
    "except ImportError:\n",
    "    _HAS_STATS_LIBS = False\n",
    "    print(\"Warning: scipy or statsmodels not available. \"\n",
    "          \"Some diagnostics will be limited.\")\n",
    "\n",
    "from scipy.stats import f_oneway, ttest_ind\n",
    "\n",
    "\n",
    "\n",
    "def get_column_groups() -> dict:\n",
    "    \"\"\"\n",
    "    Return a mapping of column-type → list of columns,\n",
    "    based on the canonical schema in src.features.feature_selection.cols.\n",
    "    \"\"\"\n",
    "    return cols.as_dict()\n",
    "\n",
    "def check_nulls(df: pd.DataFrame):\n",
    "    # Identify columns with null values\n",
    "    null_columns = df.columns[df.isnull().any()].tolist()\n",
    "    \n",
    "    # Output the columns with null values\n",
    "    if null_columns:\n",
    "        print(\"Columns with null values:\", null_columns)\n",
    "    else:\n",
    "        print(\"No columns with null values.\")\n",
    "\n",
    "\n",
    "def quick_pulse_check(\n",
    "    df: pd.DataFrame,\n",
    "    velo_col: str = \"exit_velo\",\n",
    "    group_col: str = \"batter_id\",\n",
    "    level_col: str = \"level_abbr\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Print a quick summary table:\n",
    "      - total rows\n",
    "      - unique batters\n",
    "      - overall median exit_velo\n",
    "      - median exit_velo by level\n",
    "      - distribution of events per batter (median, 25th pct)\n",
    "      - distribution of seasons per batter\n",
    "      - pearson correlations of velo with launch_angle & hangtime\n",
    "    Returns a pd.DataFrame with those metrics.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    total_rows = len(df)\n",
    "    n_batters = df[group_col].nunique()\n",
    "    overall_med = df[velo_col].median()\n",
    "\n",
    "    # median by level\n",
    "    med_by_level = df.groupby(level_col)[velo_col].median()\n",
    "\n",
    "    # events per batter\n",
    "    ev_per = df[group_col].value_counts()\n",
    "    ev_stats = ev_per.quantile([0.25, 0.5]).to_dict()\n",
    "\n",
    "    # seasons per batter\n",
    "    seasons_per = df.groupby(group_col)[\"season\"].nunique()\n",
    "    seasons_stats = seasons_per.value_counts().sort_index().to_dict()\n",
    "\n",
    "    # basic correlations\n",
    "    corr = df[[velo_col, \"launch_angle\", \"hangtime\"]].corr()[velo_col].drop(velo_col)\n",
    "\n",
    "    # Build a summary table\n",
    "    metrics = [\n",
    "        \"Total rows\",\n",
    "        \"Unique batters\",\n",
    "        \"Overall median EV\",\n",
    "    ]\n",
    "    values = [\n",
    "        total_rows,\n",
    "        n_batters,\n",
    "        overall_med,\n",
    "    ]\n",
    "    \n",
    "    # Add level-specific metrics\n",
    "    for lvl in med_by_level.index:\n",
    "        metrics.append(f\"Median EV @ {lvl}\")\n",
    "        values.append(med_by_level[lvl])\n",
    "    \n",
    "    # Add batter event metrics\n",
    "    metrics.extend([\n",
    "        \"Events per batter (25th pct)\",\n",
    "        \"Events per batter (median)\",\n",
    "    ])\n",
    "    values.extend([\n",
    "        ev_stats.get(0.25, \"N/A\"),\n",
    "        ev_stats.get(0.5, \"N/A\"),\n",
    "    ])\n",
    "    \n",
    "    # Add season distribution\n",
    "    for season_count, count in seasons_stats.items():\n",
    "        metrics.append(f\"Batters with {season_count} season(s)\")\n",
    "        values.append(count)\n",
    "    \n",
    "    # Add correlations\n",
    "    metrics.extend([\n",
    "        \"ρ(exit_velo, launch_angle)\",\n",
    "        \"ρ(exit_velo, hangtime)\",\n",
    "    ])\n",
    "    values.extend([\n",
    "        corr.get(\"launch_angle\", \"N/A\"),\n",
    "        corr.get(\"hangtime\", \"N/A\"),\n",
    "    ])\n",
    "\n",
    "    table = pd.DataFrame({\n",
    "        \"Metric\": metrics,\n",
    "        \"Value\": values\n",
    "    })\n",
    "    \n",
    "    print(table.to_string(index=False))\n",
    "    return table\n",
    "\n",
    "\n",
    "def red_flag_small_samples(df: pd.DataFrame,\n",
    "                           group_col: str = \"batter_id\",\n",
    "                           threshold: int = 15) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Identify batters with fewer than `threshold` events.\n",
    "    Returns a Series of counts indexed by batter_id.\n",
    "    \"\"\"\n",
    "    counts = df[group_col].value_counts()\n",
    "    small = counts[counts < threshold]\n",
    "    print(f\"> Batters with fewer than {threshold} events: {len(small)}\")\n",
    "    if len(small) > 0:\n",
    "        print(f\"  First few: {', '.join(map(str, small.index[:5]))}\")\n",
    "    return small\n",
    "\n",
    "\n",
    "def red_flag_level_effect(df: pd.DataFrame,\n",
    "                          level_col: str = \"level_abbr\",\n",
    "                          velo_col: str = \"exit_velo\") -> tuple:\n",
    "    \"\"\"\n",
    "    One-way ANOVA of exit_velo across levels.\n",
    "    Returns (F-statistic, p-value) or (None, None) if scipy is not available.\n",
    "    \"\"\"\n",
    "    if not _HAS_STATS_LIBS:\n",
    "        print(\"> ANOVA on exit_velo by level: scipy not available\")\n",
    "        print(\"> Basic level summary instead:\")\n",
    "        summary = df.groupby(level_col)[velo_col].agg(['mean', 'std', 'count'])\n",
    "        print(summary)\n",
    "        return None, None\n",
    "    \n",
    "    groups = [\n",
    "        df[df[level_col] == lvl][velo_col].dropna()\n",
    "        for lvl in df[level_col].unique()\n",
    "    ]\n",
    "    F, p = stats.f_oneway(*groups)\n",
    "    print(f\"> ANOVA on {velo_col} by {level_col}: F={F:.3f}, p={p:.3e}\")\n",
    "    return F, p\n",
    "\n",
    "\n",
    "def diag_age_effect(df: pd.DataFrame,\n",
    "                    age_col: str = \"age_centered\",\n",
    "                    velo_col: str = \"exit_velo\") -> np.ndarray | None:\n",
    "    \"\"\"\n",
    "    LOWESS smoothing of exit_velo vs. age_centered.\n",
    "    Returns the smoothed array or None if statsmodels is not available.\n",
    "    \"\"\"\n",
    "    if not _HAS_STATS_LIBS:\n",
    "        print(\"> Age effect analysis: statsmodels not available\")\n",
    "        print(\"> Basic correlation instead:\")\n",
    "        corr = df[[age_col, velo_col]].corr().iloc[0, 1]\n",
    "        print(f\"Correlation between {age_col} and {velo_col}: {corr:.3f}\")\n",
    "        return None\n",
    "    \n",
    "    # Run LOWESS smoothing\n",
    "    smooth_result = lowess(df[velo_col], df[age_col])\n",
    "    \n",
    "    # Plot the result\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.scatter(df[age_col], df[velo_col], alpha=0.1, s=1, color='gray')\n",
    "    plt.plot(\n",
    "        smooth_result[:, 0], \n",
    "        smooth_result[:, 1], \n",
    "        'r-', \n",
    "        linewidth=2, \n",
    "        label=\"LOWESS fit\"\n",
    "    )\n",
    "    plt.xlabel(age_col)\n",
    "    plt.ylabel(velo_col)\n",
    "    plt.title(\"Age effect (LOWESS)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return smooth_result\n",
    "\n",
    "\n",
    "def diag_time_series_dw(\n",
    "    df: pd.DataFrame,\n",
    "    time_col: str = \"season\",\n",
    "    group_col: str = \"batter_id\",\n",
    "    velo_col: str = \"exit_velo\"\n",
    ") -> pd.Series | None:\n",
    "    \"\"\"\n",
    "    Compute Durbin–Watson on each batter's time series of mean exit_velo.\n",
    "    Returns a Series of DW statistics or None if statsmodels is not available.\n",
    "    \"\"\"\n",
    "    if not _HAS_STATS_LIBS:\n",
    "        print(\"> Time series analysis: statsmodels not available\")\n",
    "        return None\n",
    "    \n",
    "    # Create pivot table of seasons (columns) by batters (rows)\n",
    "    pivot = (\n",
    "        df\n",
    "        .groupby([group_col, time_col])[velo_col]\n",
    "        .mean()\n",
    "        .unstack(fill_value=np.nan)\n",
    "    )\n",
    "    \n",
    "    # Only process batters with at least 3 seasons\n",
    "    valid_batters = pivot.dropna(thresh=3).index\n",
    "    if len(valid_batters) == 0:\n",
    "        print(\"> No batters with sufficient seasons for Durbin-Watson test\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate DW statistic for each valid batter\n",
    "    dw_stats = {}\n",
    "    for batter in valid_batters:\n",
    "        series = pivot.loc[batter].dropna()\n",
    "        if len(series) >= 3:  # Recheck after dropna\n",
    "            dw = durbin_watson(series)\n",
    "            dw_stats[batter] = dw\n",
    "    \n",
    "    dw_series = pd.Series(dw_stats)\n",
    "    print(\n",
    "        f\"> Mean Durbin–Watson across {len(dw_series)} batters: \"\n",
    "        f\"{dw_series.mean():.3f}\"\n",
    "    )\n",
    "    print(\"> DW < 1.5 suggests positive autocorrelation\")\n",
    "    print(\"> DW > 2.5 suggests negative autocorrelation\")\n",
    "    print(\"> DW ≈ 2.0 suggests no autocorrelation\")\n",
    "    \n",
    "    return dw_series\n",
    "\n",
    "\n",
    "def check_red_flags(df: pd.DataFrame, \n",
    "                    sample_threshold: int = 15) -> dict:\n",
    "    \"\"\"\n",
    "    Run all red flag checks and return the results in a dictionary.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Check for small sample sizes\n",
    "    small_samples = red_flag_small_samples(df, threshold=sample_threshold)\n",
    "    results['small_samples'] = small_samples\n",
    "    \n",
    "    # Check for level effects\n",
    "    f_stat, p_val = red_flag_level_effect(df)\n",
    "    results['level_effect'] = {\n",
    "        'f_statistic': f_stat,\n",
    "        'p_value': p_val\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_distributions(df: pd.DataFrame,\n",
    "                       velo_col: str = \"exit_velo\",\n",
    "                       by: str = \"level_abbr\"):\n",
    "    \"\"\"\n",
    "    Histogram of `velo_col` faceted by `by`.\n",
    "    Returns the Matplotlib figure so callers can save or show it.\n",
    "    \"\"\"\n",
    "    groups = df[by].unique()\n",
    "    fig, axes = plt.subplots(len(groups), 1,\n",
    "                             figsize=(6, 2.8 * len(groups)),\n",
    "                             sharex=True)\n",
    "    for ax, grp in zip(axes, groups):\n",
    "        ax.hist(df[df[by] == grp][velo_col], bins=30, alpha=0.75)\n",
    "        ax.set_title(f\"{by} = {grp} (n={len(df[df[by] == grp])})\")\n",
    "        ax.set_xlabel(velo_col)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_correlations(df: pd.DataFrame, cols: list[str]):\n",
    "    \"\"\"\n",
    "    Heat-map of Pearson correlations for `cols`.\n",
    "    \"\"\"\n",
    "    corr = df[cols].corr()\n",
    "    fig, ax = plt.subplots(figsize=(0.6 * len(cols) + 2,\n",
    "                                    0.6 * len(cols) + 2))\n",
    "    im = ax.imshow(corr, vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "    fig.colorbar(im, ax=ax, shrink=0.8)\n",
    "    ax.set_xticks(range(len(cols)), cols, rotation=90)\n",
    "    ax.set_yticks(range(len(cols)), cols)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_time_trends(df: pd.DataFrame,\n",
    "                     time_col: str = \"season\",\n",
    "                     group_col: str = \"batter_id\",\n",
    "                     velo_col: str = \"exit_velo\",\n",
    "                     sample: int = 50):\n",
    "    \"\"\"\n",
    "    Plot mean exit-velo over time for a random sample of batters.\n",
    "    \"\"\"\n",
    "    batters = df[group_col].unique()\n",
    "    chosen = np.random.choice(batters,\n",
    "                              min(sample, len(batters)),\n",
    "                              replace=False)\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    for b in chosen:\n",
    "        series = (\n",
    "            df[df[group_col] == b]\n",
    "            .groupby(time_col)[velo_col]\n",
    "            .mean()\n",
    "        )\n",
    "        ax.plot(series.index, series.values, alpha=0.3)\n",
    "    ax.set_xlabel(time_col)\n",
    "    ax.set_ylabel(velo_col)\n",
    "    ax.set_title(\"Sample batter exit-velo over time\")\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def summarize_numeric_vs_target(\n",
    "    df: pd.DataFrame,\n",
    "    numeric_cols: list[str] | None = None,\n",
    "    target_col: str = \"exit_velo\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summarise each numeric predictor against the target.\n",
    "\n",
    "    Returns a DataFrame indexed by feature with:\n",
    "      n          – number of non‑null pairs\n",
    "      pearson_r  – Pearson correlation coefficient\n",
    "    \"\"\"\n",
    "    # --- Pull fresh lists from the schema every time -----------------\n",
    "    groups = cols.as_dict()\n",
    "\n",
    "    if numeric_cols is None:\n",
    "        numeric_cols = groups.get(\"numerical\", [])\n",
    "\n",
    "    # --- Clean the list ---------------------------------------------\n",
    "    numeric_cols = [\n",
    "        c for c in numeric_cols\n",
    "        if c != target_col and c in df.columns      # ❶ exclude target, ❷ guard\n",
    "    ]\n",
    "\n",
    "    records = []\n",
    "    for col in numeric_cols:\n",
    "        sub = df[[col, target_col]].dropna()\n",
    "        if sub.empty:               # skip columns that are all‑NA\n",
    "            continue\n",
    "        r = sub[col].corr(sub[target_col])\n",
    "        records.append({\"feature\": col, \"n\": len(sub), \"pearson_r\": r})\n",
    "\n",
    "    result = (\n",
    "        pd.DataFrame.from_records(records)\n",
    "        .set_index(\"feature\")\n",
    "        .sort_values(\"pearson_r\", ascending=False)\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Numeric vs target correlations ===\")\n",
    "    print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def plot_numeric_vs_target(\n",
    "    df: pd.DataFrame,\n",
    "    numeric_cols: list[str] | None = None,\n",
    "    target_col: str = \"exit_velo\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Scatter plots of each numeric predictor vs the target with r‑value in title.\n",
    "    \"\"\"\n",
    "    summary = summarize_numeric_vs_target(df, numeric_cols, target_col)\n",
    "    for feature, row in summary.iterrows():\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.scatter(\n",
    "            df[feature], df[target_col],\n",
    "            alpha=0.3, s=5, edgecolors=\"none\"\n",
    "        )\n",
    "        plt.title(f\"{feature} vs {target_col}  (r = {row['pearson_r']:.2f})\")\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(target_col)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def summarize_categorical_vs_target(\n",
    "    df: pd.DataFrame,\n",
    "    cat_cols: list[str] | None = None,\n",
    "    target_col: str = \"exit_velo\"\n",
    ") -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    For each categorical feature, returns a DataFrame of:\n",
    "      count, mean, median, std of the target by category.\n",
    "    \"\"\"\n",
    "    groups = get_column_groups()\n",
    "    if cat_cols is None:\n",
    "        cat_cols = groups.get(\"categorical\", [])\n",
    "\n",
    "    summaries: dict[str, pd.DataFrame] = {}\n",
    "    for col in cat_cols:\n",
    "        stats = (\n",
    "            df\n",
    "            .groupby(col)[target_col]\n",
    "            .agg(count=\"count\", mean=\"mean\", median=\"median\", std=\"std\")\n",
    "            .sort_values(\"count\", ascending=False)\n",
    "        )\n",
    "        print(f\"\\n=== {col} vs {target_col} summary ===\")\n",
    "        print(stats)\n",
    "        summaries[col] = stats\n",
    "    return summaries\n",
    "\n",
    "\n",
    "def plot_categorical_vs_target(\n",
    "    df: pd.DataFrame,\n",
    "    cat_cols: list[str] | None = None,\n",
    "    target_col: str = \"exit_velo\"\n",
    "):\n",
    "    \"\"\"\n",
    "    For each categorical feature, draw a box‑plot of the target by category.\n",
    "    \"\"\"\n",
    "    groups = get_column_groups()\n",
    "    if cat_cols is None:\n",
    "        cat_cols = groups.get(\"categorical\", [])\n",
    "\n",
    "    for col in cat_cols:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        df.boxplot(column=target_col, by=col, vert=False,\n",
    "                   grid=False, patch_artist=True)\n",
    "        plt.title(f\"{target_col} by {col}\")\n",
    "        plt.suptitle(\"\")           # remove pandas' automatic suptitle\n",
    "        plt.xlabel(target_col)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def examine_and_filter_by_sample_size(\n",
    "    df: pd.DataFrame,\n",
    "    count_col: str = \"exit_velo\",\n",
    "    group_col: str = \"batter_id\",\n",
    "    season_col: str = \"season\",\n",
    "    percentile: float = 0.05,\n",
    "    min_count: int | None = None,\n",
    "    filter_df: bool = False,\n",
    ") -> tuple[dict[int, pd.DataFrame], pd.DataFrame | None]:\n",
    "    \"\"\"\n",
    "    For each season:\n",
    "      - compute per-batter count, mean, std of `count_col`\n",
    "      - pick cutoff: min_count if provided, else the `percentile` quantile\n",
    "      - print diagnostics\n",
    "      - plot histograms *safely* (drops NaNs first)\n",
    "    Returns:\n",
    "      - summaries: dict season → per-batter summary DataFrame\n",
    "      - filtered_df: if filter_df, the original df filtered to batters ≥ cutoff\n",
    "    \"\"\"\n",
    "    summaries: dict[int, pd.DataFrame] = {}\n",
    "    mask_keep: list[pd.Series] = []\n",
    "\n",
    "    for season, sub in df.groupby(season_col):\n",
    "        # 1) per-batter summary (count *non-NA* exit_velo)\n",
    "        summary = (\n",
    "            sub\n",
    "            .groupby(group_col)[count_col]\n",
    "            .agg(count=\"count\", mean=\"mean\", std=\"std\")\n",
    "            .sort_values(\"count\")\n",
    "        )\n",
    "        summaries[season] = summary\n",
    "\n",
    "        # 2) determine cutoff\n",
    "        cutoff = min_count if min_count is not None else int(summary[\"count\"].quantile(percentile))\n",
    "        small = summary[summary[\"count\"] < cutoff]\n",
    "        large = summary[summary[\"count\"] >= cutoff]\n",
    "\n",
    "        # 3) diagnostics\n",
    "        print(f\"\\n=== Season {season} (cutoff = {cutoff}) ===\")\n",
    "        print(f\"  small (<{cutoff} events): {len(small)} batters\")\n",
    "        print(small[[\"count\",\"mean\",\"std\"]].describe(), \"\\n\")\n",
    "        print(f\"  large (≥{cutoff} events): {len(large)} batters\")\n",
    "        print(large[[\"count\",\"mean\",\"std\"]].describe())\n",
    "\n",
    "        # 4) **safe plotting**: drop NaNs, skip if nothing to plot\n",
    "        small_means = small[\"mean\"].dropna()\n",
    "        large_means = large[\"mean\"].dropna()\n",
    "\n",
    "        if small_means.empty and large_means.empty:\n",
    "            print(f\"  ⚠️  Season {season}: no valid per-batter means to plot\")\n",
    "        else:\n",
    "            plt.figure(figsize=(8, 3))\n",
    "            if not small_means.empty:\n",
    "                plt.hist(small_means, bins=30, alpha=0.6, label=f\"n<{cutoff}\")\n",
    "            if not large_means.empty:\n",
    "                plt.hist(large_means, bins=30, alpha=0.6, label=f\"n≥{cutoff}\")\n",
    "            plt.title(f\"Season {season}: per-batter EV means\")\n",
    "            plt.xlabel(\"Mean exit_velo\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # 5) build mask to keep only large-sample batters\n",
    "        if filter_df:\n",
    "            keep_ids = large.index\n",
    "            mask_keep.append(\n",
    "                (df[season_col] == season) &\n",
    "                (df[group_col].isin(keep_ids))\n",
    "            )\n",
    "\n",
    "    # 6) combine masks and filter\n",
    "    filtered_df = None\n",
    "    if filter_df and mask_keep:\n",
    "        combined = pd.concat(mask_keep, axis=1).any(axis=1)\n",
    "        filtered_df = df[combined].copy()\n",
    "\n",
    "    return summaries, filtered_df\n",
    "\n",
    "\n",
    "\n",
    "def hypothesis_test(df, feature, target=\"exit_velo\", test_type=\"anova\"):\n",
    "    \"\"\"\n",
    "    Perform hypothesis tests for feature significance.\n",
    "    \"\"\"\n",
    "    if test_type == \"anova\":\n",
    "        groups = [df[df[feature] == cat][target] for cat in df[feature].unique()]\n",
    "        F, p = f_oneway(*groups)\n",
    "        print(f\"ANOVA: F={F:.3f}, p={p:.3e}\")\n",
    "        return F, p\n",
    "    elif test_type == \"ttest\":\n",
    "        group1 = df[df[feature] == 0][target]\n",
    "        group2 = df[df[feature] == 1][target]\n",
    "        t, p = ttest_ind(group1, group2)\n",
    "        print(f\"T-test: t={t:.3f}, p={p:.3e}\")\n",
    "        return t, p\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    from src.data.load_data import load_raw\n",
    "    from src.features.feature_engineering import feature_engineer\n",
    "\n",
    "    raw_path = \"data/Research Data Project/Research Data Project/exit_velo_project_data.csv\"\n",
    "    df = load_raw(raw_path)\n",
    "    print(df.head())\n",
    "    print(df.columns)\n",
    "\n",
    "    # --- inspect nulls in the raw data ---\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    if null_counts.empty:\n",
    "        print(\"✅  No missing values in raw data.\")\n",
    "    else:\n",
    "        print(\"=== Raw data null counts ===\")\n",
    "        for col, cnt in null_counts.items():\n",
    "            print(f\" • {col!r}: {cnt} missing\")\n",
    "    df_fe = feature_engineer(df)\n",
    "\n",
    "    print(\"Raw →\", df.shape, \"//  Feature‑engineered →\", df_fe.shape)\n",
    "    print(df_fe.head())\n",
    "\n",
    "    # singleton instance people can import as `cols`\n",
    "    cols = _ColumnSchema()\n",
    "\n",
    "    __all__ = [\"cols\"]\n",
    "    print(\"ID columns:         \", cols.id())\n",
    "    print(\"Ordinal columns:    \", cols.ordinal())\n",
    "    print(\"Nominal columns:    \", cols.nominal())\n",
    "    print(\"All categorical:    \", cols.categorical())\n",
    "    print(\"Numerical columns:  \", cols.numerical())\n",
    "    print(\"Model features:     \", cols.model_features())\n",
    "    print(\"Target columns:  \", cols.target())\n",
    "    print(\"All raw columns:    \", cols.all_raw())\n",
    "    numericals = cols.numerical()\n",
    "    # use list‐comprehension to drop target(s) from numerical features\n",
    "    numericals_without_y = [c for c in numericals if c not in cols.target()]\n",
    "\n",
    "\n",
    "    print(\"\\n===== check on small samples =====\")\n",
    "    summaries, _ = examine_and_filter_by_sample_size(df, percentile=0.05)\n",
    "    summaries, df_filtered = examine_and_filter_by_sample_size(\n",
    "        df, percentile=0.05, min_count=15, filter_df=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Example usage\n",
    "    print(\"\\n===== NULLS CHECK =====\")\n",
    "    check_nulls(df_fe)\n",
    "    \n",
    "    print(\"\\n===== QUICK PULSE CHECK =====\")\n",
    "    quick_pulse_check(df_fe)\n",
    "    \n",
    "    print(\"\\n===== RED FLAGS CHECK =====\")\n",
    "    check_red_flags(df_fe)\n",
    "    \n",
    "    print(\"\\n===== AGE EFFECT ANALYSIS =====\")\n",
    "    diag_age_effect(df_fe, age_col=\"age\")\n",
    "    \n",
    "    print(\"\\n===== TIME SERIES ANALYSIS =====\")\n",
    "    diag_time_series_dw(df_fe)\n",
    "    \n",
    "    print(\"\\n===== PLOTTING =====\")\n",
    "    fig1 = plot_distributions(df_fe, by=\"hit_type\")\n",
    "    fig2 = plot_correlations(df_fe, numericals)  # Using cols schema\n",
    "    fig3 = plot_time_trends(df_fe, sample=20)\n",
    "\n",
    "\n",
    "    # — Numeric features —\n",
    "    num_summary = summarize_numeric_vs_target(df_fe)\n",
    "    plot_numeric_vs_target(df_fe)\n",
    "\n",
    "    # — Categorical features —\n",
    "    cat_summary = summarize_categorical_vs_target(df_fe)\n",
    "    plot_categorical_vs_target(df_fe)\n",
    "\n",
    "    # Example: Test if age has significant effect\n",
    "    hypothesis_test(df_fe, feature=\"age_bin\", test_type=\"anova\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/features/feature_normalization.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/features/feature_normalization.py\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    from src.data.load_data import load_raw\n",
    "    from src.features.feature_engineering import feature_engineer\n",
    "\n",
    "    raw_path = \"data/Research Data Project/Research Data Project/exit_velo_project_data.csv\"\n",
    "    df = load_raw(raw_path)\n",
    "    print(df.head())\n",
    "    print(df.columns)\n",
    "\n",
    "    # --- inspect nulls in the raw data ---\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    if null_counts.empty:\n",
    "        print(\"✅  No missing values in raw data.\")\n",
    "    else:\n",
    "        print(\"=== Raw data null counts ===\")\n",
    "        for col, cnt in null_counts.items():\n",
    "            print(f\" • {col!r}: {cnt} missing\")\n",
    "    df_fe = feature_engineer(df)\n",
    "\n",
    "    print(\"Raw →\", df.shape, \"//  Feature‑engineered →\", df_fe.shape)\n",
    "    print(df_fe.head())\n",
    "\n",
    "    # singleton instance people can import as `cols`\n",
    "    cols = _ColumnSchema()\n",
    "\n",
    "    __all__ = [\"cols\"]\n",
    "    print(\"ID columns:         \", cols.id())\n",
    "    print(\"Ordinal columns:    \", cols.ordinal())\n",
    "    print(\"Nominal columns:    \", cols.nominal())\n",
    "    print(\"All categorical:    \", cols.categorical())\n",
    "    print(\"Numerical columns:  \", cols.numerical())\n",
    "    print(\"Model features:     \", cols.model_features())\n",
    "    print(\"Target columns:  \", cols.target())\n",
    "    print(\"All raw columns:    \", cols.all_raw())\n",
    "    numericals = cols.numerical()\n",
    "    # use list‐comprehension to drop target(s) from numerical features\n",
    "    numericals_without_y = [c for c in numericals if c not in cols.target()]\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/features/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/features/preprocess.py\n",
    "\"\"\"\n",
    "Preprocessing module for exit velocity pipeline.\n",
    "Supports multiple model types (linear, XGBoost, PyMC, etc.) with\n",
    "automatic ordinal-category detection from the data.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa: F401\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "from src.data.ColumnSchema import _ColumnSchema\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "# Numeric & nominal pipelines (unchanged)\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "numeric_linear = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median', add_indicator=True)),\n",
    "    ('scale', StandardScaler()),\n",
    "])\n",
    "numeric_iterative = Pipeline([\n",
    "    ('impute', IterativeImputer(random_state=0, add_indicator=True)),\n",
    "    ('scale', StandardScaler()),\n",
    "])\n",
    "nominal_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value='MISSING')),\n",
    "    ('encode', OneHotEncoder(drop='first', handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "# Dynamic preprocess functions\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "# src/features/preprocess.py\n",
    "\n",
    "def fit_preprocessor(\n",
    "    df: pd.DataFrame,\n",
    "    model_type: str = \"linear\",\n",
    "    debug: bool = False,\n",
    ") -> tuple[np.ndarray, pd.Series, ColumnTransformer]:\n",
    "    \"\"\"\n",
    "    Build & fit the preprocessing ColumnTransformer on the *full* training data.\n",
    "    Returns (X_matrix, y, fitted_transformer).\n",
    "    \"\"\"\n",
    "    cols = _ColumnSchema()\n",
    "    TARGET = cols.target()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1. filter rows & coerce numerics\n",
    "    # ------------------------------------------------------------\n",
    "    df = df[df[\"hit_type\"].str.upper() != \"BUNT\"].copy()\n",
    "    df = df.dropna(subset=[TARGET])\n",
    "    num_feats = [c for c in cols.numerical() if c != TARGET]\n",
    "    df[num_feats] = df[num_feats].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # engineered auxiliaries\n",
    "    df[\"age_centered\"] = df[\"age\"] - df[\"age\"].median()\n",
    "    df[\"level_idx\"] = df[\"level_abbr\"].map({\"AA\": 0, \"AAA\": 1, \"MLB\": 2})\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2. Prepare X, y as DATAFRAMES (keeps column names)\n",
    "    # ------------------------------------------------------------\n",
    "    ord_feats = cols.ordinal()\n",
    "    nom_feats = cols.nominal()\n",
    "    X = df[num_feats + ord_feats + nom_feats]\n",
    "    y = df[TARGET]\n",
    "\n",
    "    # force all ordinal columns to string so categories are comparable\n",
    "    X[ord_feats] = (\n",
    "        X[ord_feats]\n",
    "        .astype(str)\n",
    "        .where(X[ord_feats].notna(), other=np.nan)  # keep NaNs\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3. Compute *global* ordinal category lists\n",
    "    # ------------------------------------------------------------\n",
    "    ordinal_categories = []\n",
    "    for c in ord_feats:\n",
    "        cats = (\n",
    "            X[c].dropna().unique().tolist()\n",
    "        )\n",
    "        if \"MISSING\" not in cats:\n",
    "            cats.append(\"MISSING\")\n",
    "        ordinal_categories.append(cats)\n",
    "\n",
    "    if debug:\n",
    "        print(\"Detected ordinal categories:\", list(zip(ord_feats, ordinal_categories)))\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4. Build pipelines\n",
    "    # ------------------------------------------------------------\n",
    "    ordinal_pipe = Pipeline(\n",
    "        [\n",
    "            (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"MISSING\")),\n",
    "            (\n",
    "                \"encode\",\n",
    "                OrdinalEncoder(\n",
    "                    categories=ordinal_categories,\n",
    "                    handle_unknown=\"use_encoded_value\",\n",
    "                    unknown_value=-1,\n",
    "                    dtype=\"int32\",\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    numeric_pipe = (\n",
    "        numeric_linear if model_type == \"linear\" else numeric_iterative\n",
    "    )\n",
    "\n",
    "    ct = ColumnTransformer(\n",
    "        [\n",
    "            (\"num\", numeric_pipe, num_feats),\n",
    "            (\"ord\", ordinal_pipe, ord_feats),\n",
    "            (\"nom\", nominal_pipe, nom_feats),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "\n",
    "    X_mat = ct.fit_transform(X, y)  # still returns a NumPy array\n",
    "    return X_mat, y, ct\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def transform_preprocessor(\n",
    "    df: pd.DataFrame,\n",
    "    transformer: ColumnTransformer,\n",
    ") -> tuple[np.ndarray, pd.Series]:\n",
    "    \"\"\"\n",
    "    Apply an already‑fitted transformer to *any* new DataFrame.\n",
    "    Unseen ordinal categories are coerced to 'MISSING' first.\n",
    "    \"\"\"\n",
    "    cols = _ColumnSchema()\n",
    "    TARGET = cols.target()\n",
    "    num_feats = [c for c in cols.numerical() if c != TARGET]\n",
    "    ord_feats = cols.ordinal()\n",
    "    nom_feats = cols.nominal()\n",
    "\n",
    "    df = df.dropna(subset=[TARGET]).copy()\n",
    "    df[num_feats] = df[num_feats].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df[\"age_centered\"] = df[\"age\"] - df[\"age\"].median()\n",
    "    df[\"level_idx\"] = df[\"level_abbr\"].map({\"AA\": 0, \"AAA\": 1, \"MLB\": 2})\n",
    "\n",
    "    X = df[num_feats + ord_feats + nom_feats]\n",
    "    y = df[TARGET]\n",
    "\n",
    "    # unseen ordinals → 'MISSING'\n",
    "    X[ord_feats] = (\n",
    "        X[ord_feats]\n",
    "        .astype(str)\n",
    "        .where(X[ord_feats].notna(), other=\"MISSING\")\n",
    "    )\n",
    "\n",
    "    X_mat = transformer.transform(X)  # no warnings now\n",
    "    return X_mat, y\n",
    "\n",
    "\n",
    "\n",
    "def inverse_transform_preprocessor(\n",
    "    X_trans: np.ndarray,\n",
    "    transformer: ColumnTransformer\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Invert each block of a ColumnTransformer back to its original features,\n",
    "    based on the exact column lists we passed in.\n",
    "    \"\"\"\n",
    "    import numpy as np, pandas as pd\n",
    "\n",
    "    # 1) Flatten the lists we gave each transformer to recover original feature order\n",
    "    orig_features: list[str] = []\n",
    "    for name, _, cols in transformer.transformers_:\n",
    "        if cols == 'drop':\n",
    "            continue\n",
    "        orig_features.extend(cols)\n",
    "\n",
    "    parts = []\n",
    "    start = 0\n",
    "    n_rows = X_trans.shape[0]\n",
    "\n",
    "    # 2) For each transformer, slice & inverse-transform\n",
    "    for name, trans, cols in transformer.transformers_:\n",
    "        if cols == 'drop':\n",
    "            continue\n",
    "\n",
    "        fitted = transformer.named_transformers_[name]\n",
    "\n",
    "        # how many columns did it produce?\n",
    "        dummy = np.zeros((1, len(cols)))\n",
    "        try:\n",
    "            out = fitted.transform(dummy)\n",
    "        except Exception:\n",
    "            out = dummy\n",
    "        n_out = out.shape[1]\n",
    "\n",
    "        block = X_trans[:, start:start + n_out]\n",
    "        start += n_out\n",
    "\n",
    "        # apply inverse_transform\n",
    "        if trans == 'passthrough':\n",
    "            inv = block\n",
    "        elif name == 'num':\n",
    "            scaler = fitted.named_steps['scale']\n",
    "            inv_full = scaler.inverse_transform(block)\n",
    "            inv = inv_full[:, :len(cols)]\n",
    "        else:\n",
    "            if isinstance(fitted, Pipeline):\n",
    "                last = list(fitted.named_steps.values())[-1]\n",
    "                inv = last.inverse_transform(block)\n",
    "            else:\n",
    "                inv = fitted.inverse_transform(block)\n",
    "\n",
    "        parts.append(pd.DataFrame(inv, columns=cols, index=range(n_rows)))\n",
    "\n",
    "    # 3) Concatenate & reorder\n",
    "    df_orig = pd.concat(parts, axis=1)\n",
    "    return df_orig[orig_features]\n",
    "\n",
    "def prepare_for_mixed_and_hierarchical(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Take a feature-engineered df, drop bunts & missing target,\n",
    "    add age_centered, level_idx, and make batter_id categorical.\n",
    "    \"\"\"\n",
    "    cols = _ColumnSchema()\n",
    "    TARGET = cols.target()\n",
    "\n",
    "    df = df.copy()\n",
    "    # 1) Drop bunts & missing target\n",
    "    df = df[df[\"hit_type\"].str.upper() != \"BUNT\"]\n",
    "    df = df.dropna(subset=[TARGET])\n",
    "\n",
    "    # 2) Center age & index levels\n",
    "    df[\"age_centered\"] = df[\"age\"] - df[\"age\"].median()\n",
    "    df[\"level_idx\"]   = df[\"level_abbr\"].map({\"AA\": 0, \"AAA\": 1, \"MLB\": 2})\n",
    "\n",
    "    # 3) Categorical batter_id\n",
    "    df[\"batter_id\"] = df[\"batter_id\"].astype(\"category\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# debugs:\n",
    "def summarize_categorical_missingness(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each categorical column (ordinal + nominal), compute:\n",
    "      - original_null_count / pct\n",
    "      - imputed_missing_count / pct\n",
    "    Safely handles pandas.Categorical by first adding 'MISSING' to its categories.\n",
    "    \"\"\"\n",
    "    cols    = _ColumnSchema()\n",
    "    cat_cols = cols.ordinal() + cols.nominal()\n",
    "    summary = []\n",
    "    n = len(df)\n",
    "\n",
    "    for col in cat_cols:\n",
    "        ser = df[col]\n",
    "        orig_null = ser.isna().sum()\n",
    "\n",
    "        # If it's a Categorical, add 'MISSING' as a valid category\n",
    "        if is_categorical_dtype(ser):\n",
    "            ser = ser.cat.add_categories(['MISSING'])\n",
    "\n",
    "        # Count rows that would become 'MISSING'\n",
    "        imputed_missing = ser.fillna('MISSING').eq('MISSING').sum()\n",
    "\n",
    "        summary.append({\n",
    "            'column': col,\n",
    "            'original_null_count':   orig_null,\n",
    "            'original_null_pct':     orig_null / n,\n",
    "            'imputed_missing_count': imputed_missing,\n",
    "            'imputed_missing_pct':   imputed_missing / n,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "# 6. Smoke test (only run when module executed directly)\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    from src.data.load_data import load_raw\n",
    "    from src.features.feature_engineering import feature_engineer\n",
    "\n",
    "    raw_path = \"data/Research Data Project/Research Data Project/exit_velo_project_data.csv\"\n",
    "    df = load_raw(raw_path)\n",
    "    print(df.head())\n",
    "    print(df.columns)\n",
    "\n",
    "    # --- inspect nulls in the raw data ---\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    if null_counts.empty:\n",
    "        print(\"✅  No missing values in raw data.\")\n",
    "    else:\n",
    "        print(\"=== Raw data null counts ===\")\n",
    "        for col, cnt in null_counts.items():\n",
    "            print(f\" • {col!r}: {cnt} missing\")\n",
    "    df_fe = feature_engineer(df)\n",
    "\n",
    "    print(\"Raw →\", df.shape, \"//  Feature‑engineered →\", df_fe.shape)\n",
    "    print(df_fe.head())\n",
    "\n",
    "    # singleton instance people can import as `cols`\n",
    "    cols = _ColumnSchema()\n",
    "\n",
    "    __all__ = [\"cols\"]\n",
    "    print(\"ID columns:         \", cols.id())\n",
    "    print(\"Ordinal columns:    \", cols.ordinal())\n",
    "    print(\"Nominal columns:    \", cols.nominal())\n",
    "    print(\"All categorical:    \", cols.categorical())\n",
    "    print(\"Numerical columns:  \", cols.numerical())\n",
    "    print(\"Model features:     \", cols.model_features())\n",
    "    print(\"Target columns:  \", cols.target())\n",
    "    print(\"All raw columns:    \", cols.all_raw())\n",
    "    numericals = cols.numerical()\n",
    "    # use list‐comprehension to drop target(s) from numerical features\n",
    "    numericals_without_y = [c for c in numericals if c not in cols.target()]\n",
    "\n",
    "    summary_df = summarize_categorical_missingness(df_fe)\n",
    "    print(summary_df.to_markdown(index=False))\n",
    "\n",
    "\n",
    "    # check nulls\n",
    "    print(\"🛠️  Nulls in X before fit_transform:\")\n",
    "    null_counts = df_fe.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    if null_counts.empty:\n",
    "        print(\"✅  No missing values after feature engineering.\")\n",
    "    else:\n",
    "        print(\"=== Null counts post-engineering ===\")\n",
    "        print(null_counts)\n",
    "\n",
    "    train_df, test_df = train_test_split(df_fe, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "    # run with debug prints\n",
    "    X_train, y_train, tf = fit_preprocessor(train_df, model_type='linear', debug=True)\n",
    "    X_test,  y_test      = transform_preprocessor(test_df, tf)\n",
    "\n",
    "        \n",
    "    print(\"Processed shapes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "    # Example of inverse transform: \n",
    "    print(\"==========Example of inverse transform:==========\")\n",
    "    df_back = inverse_transform_preprocessor(X_train, tf)\n",
    "    print(\"\\n✅ Inverse‐transformed head (should mirror your original X_train):\")\n",
    "    print(df_back.head())\n",
    "    print(\"Shape:\", df_back.shape, \"→ original X_train shape before transform:\", X_train.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season level_abbr  batter_id  pitcher_id  exit_velo  launch_angle  \\\n",
      "0    2023        mlb        235        1335    95.7352       47.2362   \n",
      "1    2023        mlb       3182        1335    95.9380        4.7291   \n",
      "2    2023        mlb       3856        1988    89.1404      -16.2251   \n",
      "3    2023        mlb       2017        1988    88.7278       -6.8385   \n",
      "4    2023        mlb       1594        1988    89.2888        0.5079   \n",
      "\n",
      "   spray_angle  hangtime     hit_type batter_hand pitcher_hand  batter_height  \\\n",
      "0      -6.4422    6.4960     fly_ball           R            R             72   \n",
      "1      -4.8052    0.7806  ground_ball           L            R             75   \n",
      "2      15.2382    0.0311  ground_ball           S            R             72   \n",
      "3     -11.5988    0.1215  ground_ball           R            R             69   \n",
      "4     -22.1899    0.3802  ground_ball           R            R             73   \n",
      "\n",
      "  pitch_group outcome   age  \n",
      "0          FB     out  32.8  \n",
      "1          OS     out  29.2  \n",
      "2          OS     out  29.7  \n",
      "3          BB     out  23.4  \n",
      "4          FB     out  35.3  \n",
      "Index(['season', 'level_abbr', 'batter_id', 'pitcher_id', 'exit_velo',\n",
      "       'launch_angle', 'spray_angle', 'hangtime', 'hit_type', 'batter_hand',\n",
      "       'pitcher_hand', 'batter_height', 'pitch_group', 'outcome', 'age'],\n",
      "      dtype='object')\n",
      "=== Raw data null counts ===\n",
      " • 'exit_velo': 97979 missing\n",
      " • 'launch_angle': 9130 missing\n",
      " • 'spray_angle': 6227 missing\n",
      " • 'hangtime': 75968 missing\n",
      " • 'hit_type': 201 missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\src\\features\\feature_engineering.py:133: FutureWarning:\n",
      "\n",
      "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw → (1344651, 15) //  Feature-engineered → (1344651, 33)\n",
      "   season level_abbr  batter_id  pitcher_id  exit_velo  launch_angle  \\\n",
      "0    2023        MLB        235        1335    95.7352       47.2362   \n",
      "1    2023        MLB       3182        1335    95.9380        4.7291   \n",
      "2    2023        MLB       3856        1988    89.1404      -16.2251   \n",
      "3    2023        MLB       2017        1988    88.7278       -6.8385   \n",
      "4    2023        MLB       1594        1988    89.2888        0.5079   \n",
      "\n",
      "   spray_angle  hangtime     hit_type batter_hand  ... pitch_hand_match  \\\n",
      "0      -6.4422    6.4960     FLY_BALL           R  ...        FB_R_VS_R   \n",
      "1      -4.8052    0.7806  GROUND_BALL           L  ...        OS_L_VS_R   \n",
      "2      15.2382    0.0311  GROUND_BALL           S  ...        OS_S_VS_R   \n",
      "3     -11.5988    0.1215  GROUND_BALL           R  ...        BB_R_VS_R   \n",
      "4     -22.1899    0.3802  GROUND_BALL           R  ...        FB_R_VS_R   \n",
      "\n",
      "   player_ev_mean50 player_ev_std50 hard_hit  near_barrel  ev_la_product  \\\n",
      "0         89.923631       12.088127     True        False   13138.335054   \n",
      "1         94.109155       13.340991     True        False    9088.120396   \n",
      "2         85.266690       13.363411    False        False    6576.324096   \n",
      "3         85.389481       16.746956    False        False    7378.736940   \n",
      "4         94.849458       12.962405    False        False    8081.341782   \n",
      "\n",
      "  est_distance  ev_la_sqrt pitcher_ev_mean50 outcome_val  \n",
      "0   621.895859  114.622577         85.828920         0.0  \n",
      "1    74.889203   95.331634         91.074314         0.0  \n",
      "2     2.772266   81.094538         92.208417         0.0  \n",
      "3    10.780428   85.899575         88.391978         0.0  \n",
      "4    33.947602   89.896283         92.155127         0.0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "ID columns:          ['season', 'batter_id', 'pitcher_id']\n",
      "Ordinal columns:     ['level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val']\n",
      "Nominal columns:     ['hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel']\n",
      "All categorical:     ['level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val', 'hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel']\n",
      "Numerical columns:   ['exit_velo', 'launch_angle', 'spray_angle', 'hangtime', 'ev_la_product', 'ev_la_sqrt', 'est_distance', 'player_ev_mean50', 'player_ev_std50', 'pitcher_ev_mean50']\n",
      "Model features:      ['launch_angle', 'spray_angle', 'hangtime', 'ev_la_product', 'ev_la_sqrt', 'est_distance', 'player_ev_mean50', 'player_ev_std50', 'pitcher_ev_mean50', 'hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel', 'level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val']\n",
      "Target columns:      exit_velo\n",
      "All raw columns:     ['season', 'batter_id', 'pitcher_id', 'level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val', 'hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel', 'exit_velo', 'launch_angle', 'spray_angle', 'hangtime', 'ev_la_product', 'ev_la_sqrt', 'est_distance', 'player_ev_mean50', 'player_ev_std50', 'pitcher_ev_mean50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\src\\features\\preprocess.py:72: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessed feature matrix: 1237594 rows × 58 cols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "\n",
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "\n",
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "\n",
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning:\n",
      "\n",
      "Found unknown categories in columns [0, 1, 2, 3, 4, 5, 6] during transform. These unknown categories will be encoded as all zeros\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ inverse_transform round-trip (head):\n",
      "   launch_angle  spray_angle  hangtime  ev_la_product  ev_la_sqrt  \\\n",
      "0       47.2362      -6.4422    6.4960   13138.335054  114.622577   \n",
      "1        4.7291      -4.8052    0.7806    9088.120396   95.331634   \n",
      "2      -16.2251      15.2382    0.0311    6576.324096   81.094538   \n",
      "3       -6.8385     -11.5988    0.1215    7378.736940   85.899575   \n",
      "4        0.5079     -22.1899    0.3802    8081.341782   89.896283   \n",
      "\n",
      "   est_distance  player_ev_mean50  player_ev_std50  pitcher_ev_mean50  \\\n",
      "0    621.895859         89.923631        12.088127          85.828920   \n",
      "1     74.889203         94.109155        13.340991          91.074314   \n",
      "2      2.772266         85.266690        13.363411          92.208417   \n",
      "3     10.780428         85.389481        16.746956          88.391978   \n",
      "4     33.947602         94.849458        12.962405          92.155127   \n",
      "\n",
      "  level_abbr  ... outcome pitch_group batter_hand pitcher_hand hand_match  \\\n",
      "0        MLB  ...     OUT          FB           R            R     R_VS_R   \n",
      "1        MLB  ...     OUT          OS           L            R     L_VS_R   \n",
      "2        MLB  ...     OUT          OS           S            R     S_VS_R   \n",
      "3        MLB  ...     OUT          BB           R            R     R_VS_R   \n",
      "4        MLB  ...     OUT          FB           R            R     R_VS_R   \n",
      "\n",
      "  pitch_hand_match same_hand is_barrel hard_hit near_barrel  \n",
      "0        FB_R_VS_R      True     False     True       False  \n",
      "1        OS_L_VS_R     False     False     True       False  \n",
      "2        OS_S_VS_R     False     False    False       False  \n",
      "3        BB_R_VS_R      True     False    False       False  \n",
      "4        FB_R_VS_R      True     False    False       False  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Training baseline model…\n",
      "\n",
      "🔍 Permutation Importances:\n",
      "⏳ Computing permutation importances on 1237594 rows × 58 features\n",
      "   n_repeats=10, n_jobs=2, max_samples=0.5\n",
      "   Subsampling to 618797 rows for speed\n",
      "✅ Permutation importances computed.\n",
      "                           feature  importance_mean  importance_std\n",
      "0                     launch_angle     1.092361e+00    1.204915e-03\n",
      "1                    ev_la_product     6.638352e-01    1.492732e-03\n",
      "2                       ev_la_sqrt     6.281785e-01    1.493496e-03\n",
      "3                    hard_hit_True     5.179642e-01    1.515394e-03\n",
      "4                         hangtime     1.975298e-01    3.685625e-04\n",
      "5                     est_distance     7.467596e-02    2.102029e-04\n",
      "6                  hit_type_POP_UP     7.073581e-03    8.664476e-05\n",
      "7                 near_barrel_True     3.380596e-03    2.501599e-05\n",
      "8                           la_bin     9.795062e-05    2.035054e-06\n",
      "9                      outcome_val     3.164342e-05    1.042335e-06\n",
      "10                     spray_angle     1.453553e-05    6.594418e-07\n",
      "11       missingindicator_hangtime     1.442973e-05    1.523941e-06\n",
      "12  missingindicator_ev_la_product     8.608779e-06    3.858679e-08\n",
      "13   missingindicator_est_distance     7.267793e-06    7.467910e-07\n",
      "14                     outcome_OUT     6.575707e-06    3.434042e-07\n",
      "15                player_ev_mean50     5.019878e-06    2.426014e-07\n",
      "16                 player_ev_std50     4.308430e-06    3.257778e-07\n",
      "17               pitcher_ev_mean50     3.340218e-06    2.659228e-07\n",
      "18   missingindicator_launch_angle     3.157224e-06    6.158535e-09\n",
      "19     missingindicator_ev_la_sqrt     2.707077e-06    1.532677e-09\n",
      "20                      level_abbr     2.356268e-06    2.795724e-07\n",
      "21                outcome_HOME_RUN     2.235641e-06    1.816069e-07\n",
      "22                         age_bin     1.052397e-06    5.755315e-08\n",
      "23                       spray_bin     6.330596e-07    6.415478e-08\n",
      "24                  pitch_group_FB     5.156951e-07    5.554065e-08\n",
      "25      pitch_hand_match_FB_R_VS_R     3.985335e-07    3.404276e-08\n",
      "26                   batter_hand_R     3.460089e-07    4.971304e-08\n",
      "27      pitch_hand_match_BB_R_VS_R     3.449567e-07    3.893673e-08\n",
      "28                  same_hand_True     3.387847e-07    5.650572e-08\n",
      "29               hand_match_R_VS_R     2.951906e-07    3.237820e-08\n",
      "30                  pitcher_hand_R     2.804958e-07    2.893902e-08\n",
      "31                  pitch_group_OS     2.317248e-07    3.601424e-08\n",
      "32               hand_match_L_VS_R     2.110637e-07    3.109406e-08\n",
      "33      pitch_hand_match_FB_L_VS_R     1.995897e-07    2.733399e-08\n",
      "34      pitch_hand_match_OS_R_VS_L     1.787292e-07    5.257558e-08\n",
      "35               hand_match_R_VS_L     1.622100e-07    1.577772e-08\n",
      "36      pitch_hand_match_OS_L_VS_R     1.466428e-07    5.613333e-09\n",
      "37      pitch_hand_match_OS_R_VS_R     1.328068e-07    3.481117e-08\n",
      "38                  outcome_SINGLE     1.285483e-07    1.509510e-08\n",
      "39               hand_match_S_VS_R     1.235135e-07    1.220430e-08\n",
      "40      pitch_hand_match_FB_L_VS_L     1.230317e-07    2.587828e-08\n",
      "41                   batter_hand_S     1.174416e-07    1.509447e-08\n",
      "42      pitch_hand_match_BB_L_VS_R     1.140078e-07    2.205456e-08\n",
      "43      pitch_hand_match_FB_R_VS_L     1.134061e-07    1.173177e-08\n",
      "44      pitch_hand_match_FB_S_VS_R     1.104315e-07    6.676559e-09\n",
      "45      pitch_hand_match_OS_S_VS_R     1.027110e-07    3.379571e-09\n",
      "46      pitch_hand_match_BB_R_VS_L     9.107009e-08    3.276920e-08\n",
      "47               hand_match_S_VS_L     3.847195e-08    2.509463e-08\n",
      "48            hit_type_GROUND_BALL     3.817477e-08    1.691416e-08\n",
      "49                  is_barrel_True     3.620813e-08    1.035026e-09\n",
      "50      pitch_hand_match_FB_S_VS_L     2.390543e-08    4.847469e-09\n",
      "51                hit_type_MISSING     1.899783e-08    0.000000e+00\n",
      "52      pitch_hand_match_BB_S_VS_R     1.748791e-08    5.137699e-09\n",
      "53      pitch_hand_match_BB_S_VS_L     1.272679e-08    1.057477e-10\n",
      "54             hit_type_LINE_DRIVE     1.128873e-08    1.413384e-09\n",
      "55      pitch_hand_match_OS_L_VS_L     8.601287e-09    1.580950e-09\n",
      "56      pitch_hand_match_OS_S_VS_L     6.941761e-09    1.209175e-08\n",
      "57                  outcome_TRIPLE     2.944626e-09    1.201353e-10\n",
      "\n",
      "🔍 SHAP Importances:\n"
     ]
    }
   ],
   "source": [
    "# %%writefile src/features/feature_selection.py\n",
    "import pandas as pd\n",
    "\n",
    "# ── NEW: model and importance imports\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap\n",
    "\n",
    "from pathlib import Path\n",
    "from src.data.load_data import load_raw\n",
    "from src.features.feature_engineering import feature_engineer\n",
    "from src.data.ColumnSchema import _ColumnSchema\n",
    "# ── NEW: shapash and shapiq imports\n",
    "from shapash import SmartExplainer\n",
    "import shapiq\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def train_baseline_model(X, y):\n",
    "    \"\"\"\n",
    "    Fit a RandomForestRegressor on X, y.\n",
    "    Returns the fitted model.\n",
    "    \"\"\"\n",
    "    # You can adjust hyperparameters as needed\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def compute_permutation_importance(\n",
    "    model,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    n_repeats: int = 10,\n",
    "    n_jobs: int = 1,\n",
    "    max_samples: float | int = None,\n",
    "    random_state: int = 42,\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute permutation importances with controlled resource usage.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator\n",
    "        Fitted model implementing .predict and .score.\n",
    "    X : pd.DataFrame\n",
    "        Features.\n",
    "    y : pd.Series or array\n",
    "        Target.\n",
    "    n_repeats : int\n",
    "        Number of shuffles per feature.\n",
    "    n_jobs : int\n",
    "        Number of parallel jobs (avoid -1 on Windows).\n",
    "    max_samples : float or int, optional\n",
    "        If float in (0,1], fraction of rows to sample.\n",
    "        If int, absolute number of rows to sample.\n",
    "    random_state : int\n",
    "        Seed for reproducibility.\n",
    "    verbose : bool\n",
    "        Print debug info if True.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Columns: feature, importance_mean, importance_std.\n",
    "        Sorted descending by importance_mean.\n",
    "    \"\"\"\n",
    "    # Debug info\n",
    "    if verbose:\n",
    "        print(f\"⏳ Computing permutation importances on {X.shape[0]} rows × {X.shape[1]} features\")\n",
    "        print(f\"   n_repeats={n_repeats}, n_jobs={n_jobs}, max_samples={max_samples}\")\n",
    "\n",
    "    # Subsample if requested\n",
    "    X_sel, y_sel = X, y\n",
    "    if max_samples is not None:\n",
    "        if isinstance(max_samples, float):\n",
    "            nsamp = int(len(X) * max_samples)\n",
    "        else:\n",
    "            nsamp = int(max_samples)\n",
    "        if verbose:\n",
    "            print(f\"   Subsampling to {nsamp} rows for speed\")\n",
    "        X_sel, y_sel = resample(X, y, replace=False, n_samples=nsamp, random_state=random_state)\n",
    "\n",
    "    try:\n",
    "        result = permutation_importance(\n",
    "            model,\n",
    "            X_sel, y_sel,\n",
    "            n_repeats=n_repeats,\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "    except OSError as e:\n",
    "        # Graceful fallback to single job\n",
    "        if verbose:\n",
    "            print(f\"⚠️  OSError ({e}). Retrying with n_jobs=1\")\n",
    "        result = permutation_importance(\n",
    "            model,\n",
    "            X_sel, y_sel,\n",
    "            n_repeats=n_repeats,\n",
    "            random_state=random_state,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "\n",
    "    # Build and sort DataFrame\n",
    "    importance_df = (\n",
    "        pd.DataFrame({\n",
    "            \"feature\": X.columns,\n",
    "            \"importance_mean\": result.importances_mean,\n",
    "            \"importance_std\": result.importances_std,\n",
    "        })\n",
    "        .sort_values(\"importance_mean\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    if verbose:\n",
    "        print(\"✅ Permutation importances computed.\")\n",
    "    return importance_df\n",
    "\n",
    "\n",
    "def compute_shap_importance(model, X, nsamples=100):\n",
    "    \"\"\"\n",
    "    Compute mean absolute SHAP values per feature.\n",
    "    Returns a DataFrame sorted by importance.\n",
    "    \"\"\"\n",
    "    # DeepExplainer or TreeExplainer for tree-based models\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    # sample for speed\n",
    "    X_sample = X.sample(n=min(nsamples, len(X)), random_state=42)\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "    # For regression, shap_values is a 2D array\n",
    "    mean_abs_shap = pd.DataFrame({\n",
    "        \"feature\": X_sample.columns,\n",
    "        \"shap_importance\": np.abs(shap_values).mean(axis=0),\n",
    "    })\n",
    "    mean_abs_shap = mean_abs_shap.sort_values(\"shap_importance\", ascending=False).reset_index(drop=True)\n",
    "    return mean_abs_shap\n",
    "\n",
    "\n",
    "\n",
    "def filter_permutation_features(\n",
    "    importance_df: pd.DataFrame,\n",
    "    threshold: float\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Return features whose permutation importance_mean exceeds threshold.\n",
    "    \"\"\"\n",
    "    kept = importance_df.loc[\n",
    "        importance_df[\"importance_mean\"] > threshold, \"feature\"\n",
    "    ]\n",
    "    return kept.tolist()\n",
    "\n",
    "\n",
    "def filter_shap_features(\n",
    "    importance_df: pd.DataFrame,\n",
    "    threshold: float\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Return features whose shap_importance exceeds threshold.\n",
    "    \"\"\"\n",
    "    kept = importance_df.loc[\n",
    "        importance_df[\"shap_importance\"] > threshold, \"feature\"\n",
    "    ]\n",
    "    return kept.tolist()\n",
    "\n",
    "\n",
    "def select_final_features(\n",
    "    perm_feats: list[str],\n",
    "    shap_feats: list[str],\n",
    "    mode: str = \"intersection\"\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Combine permutation and SHAP feature lists.\n",
    "    mode=\"intersection\" for features in both lists,\n",
    "    mode=\"union\" for features in either list.\n",
    "    \"\"\"\n",
    "    set_perm = set(perm_feats)\n",
    "    set_shap = set(shap_feats)\n",
    "    if mode == \"union\":\n",
    "        final = set_perm | set_shap\n",
    "    else:\n",
    "        final = set_perm & set_shap\n",
    "    # return sorted for reproducibility\n",
    "    return sorted(final)\n",
    "\n",
    "\n",
    "\n",
    "def load_final_features(\n",
    "    file_path: str = \"data/models/features/final_features.txt\"\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Read the newline-delimited feature names file and return as a list.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as fp:\n",
    "        return [line.strip() for line in fp if line.strip()]\n",
    "\n",
    "\n",
    "def filter_to_final_features(\n",
    "    df: pd.DataFrame,\n",
    "    file_path: str = \"data/models/features/final_features.txt\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a feature-engineered DataFrame, load the final feature list,\n",
    "    then return df[ ID_cols + final_features + [target] ].\n",
    "    \"\"\"\n",
    "    # load the feature names\n",
    "    final_feats = load_final_features(file_path)\n",
    "    cols = _ColumnSchema()\n",
    "\n",
    "    keep = cols.id() + final_feats + [cols.target()]\n",
    "    missing = set(keep) - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Cannot filter: missing columns {missing}\")\n",
    "    return df[keep].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- existing loading & schema logic ---\n",
    "    raw_path = Path(\"data/Research Data Project/Research Data Project/exit_velo_project_data.csv\")\n",
    "    df = load_raw(raw_path)\n",
    "    print(df.head())\n",
    "    print(df.columns)\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    if null_counts.empty:\n",
    "        print(\"✅  No missing values in raw data.\")\n",
    "    else:\n",
    "        print(\"=== Raw data null counts ===\")\n",
    "        for col, cnt in null_counts.items():\n",
    "            print(f\" • {col!r}: {cnt} missing\")\n",
    "    df_fe = feature_engineer(df)\n",
    "    print(\"Raw →\", df.shape, \"//  Feature-engineered →\", df_fe.shape)\n",
    "    print(df_fe.head())\n",
    "\n",
    "    cols = _ColumnSchema()\n",
    "    print(\"ID columns:         \", cols.id())\n",
    "    print(\"Ordinal columns:    \", cols.ordinal())\n",
    "    print(\"Nominal columns:    \", cols.nominal())\n",
    "    print(\"All categorical:    \", cols.categorical())\n",
    "    print(\"Numerical columns:  \", cols.numerical())\n",
    "    print(\"Model features:     \", cols.model_features())\n",
    "    print(\"Target columns:     \", cols.target())\n",
    "    print(\"All raw columns:    \", cols.all_raw())\n",
    "    numericals = cols.numerical()\n",
    "    numericals_without_y = [c for c in numericals if c not in cols.target()]\n",
    "\n",
    "    # ── STEP 1: fully preprocess the engineered DataFrame ──\n",
    "    from src.features.preprocess import fit_preprocessor, inverse_transform_preprocessor\n",
    "\n",
    "    # fit_preprocessor returns (X_matrix, y, fitted_transformer)\n",
    "    X_np, y, preproc = fit_preprocessor(df_fe, model_type='linear', debug=False)\n",
    "\n",
    "    # Use the same index that y carries (only non-bunt, non-NA rows)\n",
    "    idx = y.index\n",
    "    \n",
    "    # turn that into a DataFrame with the same column names:\n",
    "    feat_names = preproc.get_feature_names_out()\n",
    "    X = pd.DataFrame(X_np, columns=feat_names, index=idx)\n",
    "    print(f\"✅ Preprocessed feature matrix: {X.shape[0]} rows × {X.shape[1]} cols\")\n",
    "\n",
    "    # (optional) confirm inverse transform lines up:\n",
    "    df_back = inverse_transform_preprocessor(X_np, preproc)\n",
    "    df_back.index = idx\n",
    "    print(\"✅ inverse_transform round-trip (head):\")\n",
    "    print(df_back.head())\n",
    "\n",
    "    # ── STEP 2: train & compute importances on *that* X ──\n",
    "    print(\"\\nTraining baseline model…\")\n",
    "    model = train_baseline_model(X, y)\n",
    "\n",
    "    print(\"\\n🔍 Permutation Importances:\")\n",
    "    perm_imp = compute_permutation_importance(\n",
    "        model, X, y,\n",
    "        n_repeats=10,\n",
    "        n_jobs=2,            # test small parallelism\n",
    "        max_samples=0.5,     # test subsampling\n",
    "        verbose=True\n",
    "    )\n",
    "    print(perm_imp)\n",
    "\n",
    "\n",
    "    print(\"\\n🔍 SHAP Importances:\")\n",
    "    shap_imp = compute_shap_importance(model, X)\n",
    "    print(shap_imp)\n",
    "\n",
    "    # ── STEP 3: threshold & select your final features ──\n",
    "    perm_thresh = 0.01\n",
    "    shap_thresh = 0.01\n",
    "    perm_feats = filter_permutation_features(perm_imp, perm_thresh)\n",
    "    shap_feats = filter_shap_features(shap_imp, shap_thresh)\n",
    "    final_feats = select_final_features(perm_feats, shap_feats, mode=\"intersection\")\n",
    "    print(f\"\\nFinal preprocessed feature list ({len(final_feats)}):\")\n",
    "    print(final_feats)\n",
    "\n",
    "    # ── STEP 4: build & save a dataset with just those features + target + IDs ──\n",
    "    df_final = pd.concat([\n",
    "        df_fe[cols.id()],\n",
    "        df_fe[[cols.target()]],\n",
    "        X[final_feats]\n",
    "    ], axis=1)\n",
    "    print(\"Final dataset shape:\", df_final.shape)\n",
    "\n",
    "    Path(\"data/models/features/final_features.txt\").write_text(\"\\n\".join(final_feats))\n",
    "    print(\"✔️ Saved feature list to final_features.txt\")\n",
    "\n",
    "\n",
    "    # Demo: filter the full df_fe back to just those features\n",
    "    df_filtered = filter_to_final_features(df_fe)\n",
    "    print(\"Filtered to final features shape:\", df_filtered.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model choices\n",
    "\n",
    "see modelling_choices.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season level_abbr  batter_id  pitcher_id  exit_velo  launch_angle  \\\n",
      "0    2023        mlb        235        1335    95.7352       47.2362   \n",
      "1    2023        mlb       3182        1335    95.9380        4.7291   \n",
      "2    2023        mlb       3856        1988    89.1404      -16.2251   \n",
      "3    2023        mlb       2017        1988    88.7278       -6.8385   \n",
      "4    2023        mlb       1594        1988    89.2888        0.5079   \n",
      "\n",
      "   spray_angle  hangtime     hit_type batter_hand pitcher_hand  batter_height  \\\n",
      "0      -6.4422    6.4960     fly_ball           R            R             72   \n",
      "1      -4.8052    0.7806  ground_ball           L            R             75   \n",
      "2      15.2382    0.0311  ground_ball           S            R             72   \n",
      "3     -11.5988    0.1215  ground_ball           R            R             69   \n",
      "4     -22.1899    0.3802  ground_ball           R            R             73   \n",
      "\n",
      "  pitch_group outcome   age  \n",
      "0          FB     out  32.8  \n",
      "1          OS     out  29.2  \n",
      "2          OS     out  29.7  \n",
      "3          BB     out  23.4  \n",
      "4          FB     out  35.3  \n",
      "Index(['season', 'level_abbr', 'batter_id', 'pitcher_id', 'exit_velo',\n",
      "       'launch_angle', 'spray_angle', 'hangtime', 'hit_type', 'batter_hand',\n",
      "       'pitcher_hand', 'batter_height', 'pitch_group', 'outcome', 'age'],\n",
      "      dtype='object')\n",
      "=== Raw data null counts ===\n",
      " • 'exit_velo': 97979 missing\n",
      " • 'launch_angle': 9130 missing\n",
      " • 'spray_angle': 6227 missing\n",
      " • 'hangtime': 75968 missing\n",
      " • 'hit_type': 201 missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\src\\features\\feature_engineering.py:133: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"pitcher_ev_mean50\"].fillna(df[\"exit_velo\"].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw → (1344651, 15) //  Feature‑engineered → (1344651, 33)\n",
      "   season level_abbr  batter_id  pitcher_id  exit_velo  launch_angle  \\\n",
      "0    2023        MLB        235        1335    95.7352       47.2362   \n",
      "1    2023        MLB       3182        1335    95.9380        4.7291   \n",
      "2    2023        MLB       3856        1988    89.1404      -16.2251   \n",
      "3    2023        MLB       2017        1988    88.7278       -6.8385   \n",
      "4    2023        MLB       1594        1988    89.2888        0.5079   \n",
      "\n",
      "   spray_angle  hangtime     hit_type batter_hand  ... pitch_hand_match  \\\n",
      "0      -6.4422    6.4960     FLY_BALL           R  ...        FB_R_VS_R   \n",
      "1      -4.8052    0.7806  GROUND_BALL           L  ...        OS_L_VS_R   \n",
      "2      15.2382    0.0311  GROUND_BALL           S  ...        OS_S_VS_R   \n",
      "3     -11.5988    0.1215  GROUND_BALL           R  ...        BB_R_VS_R   \n",
      "4     -22.1899    0.3802  GROUND_BALL           R  ...        FB_R_VS_R   \n",
      "\n",
      "   player_ev_mean50 player_ev_std50 hard_hit  near_barrel  ev_la_product  \\\n",
      "0         89.923631       12.088127     True        False   13138.335054   \n",
      "1         94.109155       13.340991     True        False    9088.120396   \n",
      "2         85.266690       13.363411    False        False    6576.324096   \n",
      "3         85.389481       16.746956    False        False    7378.736940   \n",
      "4         94.849458       12.962405    False        False    8081.341782   \n",
      "\n",
      "  est_distance  ev_la_sqrt pitcher_ev_mean50 outcome_val  \n",
      "0   621.895859  114.622577         85.828920         0.0  \n",
      "1    74.889203   95.331634         91.074314         0.0  \n",
      "2     2.772266   81.094538         92.208417         0.0  \n",
      "3    10.780428   85.899575         88.391978         0.0  \n",
      "4    33.947602   89.896283         92.155127         0.0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "ID columns:          ['season', 'batter_id', 'pitcher_id']\n",
      "Ordinal columns:     ['level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val']\n",
      "Nominal columns:     ['hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel']\n",
      "All categorical:     ['level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val', 'hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel']\n",
      "Numerical columns:   ['exit_velo', 'launch_angle', 'spray_angle', 'hangtime', 'ev_la_product', 'ev_la_sqrt', 'est_distance', 'player_ev_mean50', 'player_ev_std50', 'pitcher_ev_mean50']\n",
      "Model features:      ['launch_angle', 'spray_angle', 'hangtime', 'ev_la_product', 'ev_la_sqrt', 'est_distance', 'player_ev_mean50', 'player_ev_std50', 'pitcher_ev_mean50', 'hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel', 'level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val']\n",
      "Target columns:   exit_velo\n",
      "All raw columns:     ['season', 'batter_id', 'pitcher_id', 'level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val', 'hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel', 'exit_velo', 'launch_angle', 'spray_angle', 'hangtime', 'ev_la_product', 'ev_la_sqrt', 'est_distance', 'player_ev_mean50', 'player_ev_std50', 'pitcher_ev_mean50']\n",
      "| column           |   original_null_count |   original_null_pct |   imputed_missing_count |   imputed_missing_pct |\n",
      "|:-----------------|----------------------:|--------------------:|------------------------:|----------------------:|\n",
      "| level_abbr       |                     0 |         0           |                       0 |           0           |\n",
      "| age_bin          |                     0 |         0           |                       0 |           0           |\n",
      "| la_bin           |                  9130 |         0.00678987  |                    9130 |           0.00678987  |\n",
      "| spray_bin        |                  6227 |         0.00463094  |                    6227 |           0.00463094  |\n",
      "| outcome_val      |                 63271 |         0.0470538   |                   63271 |           0.0470538   |\n",
      "| hit_type         |                   201 |         0.000149481 |                     201 |           0.000149481 |\n",
      "| outcome          |                     0 |         0           |                       0 |           0           |\n",
      "| pitch_group      |                     0 |         0           |                       0 |           0           |\n",
      "| batter_hand      |                     0 |         0           |                       0 |           0           |\n",
      "| pitcher_hand     |                     0 |         0           |                       0 |           0           |\n",
      "| hand_match       |                     0 |         0           |                       0 |           0           |\n",
      "| pitch_hand_match |                     0 |         0           |                       0 |           0           |\n",
      "| same_hand        |                     0 |         0           |                       0 |           0           |\n",
      "| is_barrel        |                     0 |         0           |                       0 |           0           |\n",
      "| hard_hit         |                     0 |         0           |                       0 |           0           |\n",
      "| near_barrel      |                     0 |         0           |                       0 |           0           |\n",
      "🛠️  Nulls in X before fit_transform:\n",
      "=== Null counts post-engineering ===\n",
      "exit_velo         97979\n",
      "launch_angle       9130\n",
      "spray_angle        6227\n",
      "hangtime          75968\n",
      "hit_type            201\n",
      "la_bin             9130\n",
      "spray_bin          6227\n",
      "ev_la_product     97981\n",
      "est_distance     110411\n",
      "ev_la_sqrt        97981\n",
      "outcome_val       63271\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\src\\features\\preprocess.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[ord_feats] = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected ordinal categories: [('level_abbr', ['MLB', 'AAA', 'AA', 'MISSING']), ('age_bin', ['(26.3, 28.9]', '(24.5, 26.3]', '(28.9, 43.0]', '(17.099, 24.5]', 'MISSING']), ('la_bin', ['(-89.685, -10.533]', '(35.19, 89.875]', '(-10.533, 6.002]', '(19.631, 35.19]', '(6.002, 19.631]', 'MISSING']), ('spray_bin', ['(-179.916, -12.664]', '(-12.664, 9.63]', '(9.63, 179.962]', 'MISSING']), ('outcome_val', ['0.0', '1.0', '2.0', '3.0', 'MISSING'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\src\\features\\preprocess.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[ord_feats] = (\n",
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed shapes: (990200, 58) (249198, 58)\n",
      "==========Example of inverse transform:==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 2, 3, 4, 5, 6] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Inverse‐transformed head (should mirror your original X_train):\n",
      "   launch_angle  spray_angle  hangtime  ev_la_product  ev_la_sqrt  \\\n",
      "0      -20.7923     -44.3123    0.1277    3261.025299   57.105388   \n",
      "1       44.5676       3.1201    6.0871   12641.549479  112.434645   \n",
      "2       49.3999     -32.1939    4.3439    8662.978906   93.075125   \n",
      "3        0.6769       5.6467    0.3372    9277.924393   96.321983   \n",
      "4       37.1261     -26.3477    5.5243   11487.305085  107.178846   \n",
      "\n",
      "   est_distance  player_ev_mean50  player_ev_std50  pitcher_ev_mean50  \\\n",
      "0      6.017147         89.726660        14.893938          91.562006   \n",
      "1    571.834348         89.320567        19.629693          90.466646   \n",
      "2    269.950797         84.978622        15.285691          85.517696   \n",
      "3     34.501798         87.332024        18.400426          88.802587   \n",
      "4    499.184034         97.734258        11.093887          89.354354   \n",
      "\n",
      "  level_abbr  ... outcome pitch_group batter_hand pitcher_hand hand_match  \\\n",
      "0        MLB  ...     OUT          FB           R            R     R_VS_R   \n",
      "1        MLB  ...     OUT          BB           L            L     L_VS_L   \n",
      "2        MLB  ...  SINGLE          OS           L            R     L_VS_R   \n",
      "3        AAA  ...     OUT          FB           R            L     R_VS_L   \n",
      "4        MLB  ...     OUT          FB           R            L     R_VS_L   \n",
      "\n",
      "  pitch_hand_match same_hand is_barrel hard_hit near_barrel  \n",
      "0        FB_R_VS_R      True     False    False       False  \n",
      "1        BB_L_VS_L      True     False    False       False  \n",
      "2        OS_L_VS_R     False     False    False       False  \n",
      "3        FB_R_VS_L     False     False     True       False  \n",
      "4        FB_R_VS_L     False     False    False       False  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "Shape: (990200, 25) → original X_train shape before transform: (990200, 58)\n",
      "Ridge regression RMSE: 2.0336\n"
     ]
    }
   ],
   "source": [
    "# %%writefile src/models/linear.py\n",
    "\n",
    "\"\"\"\n",
    "Fast linear baselines (OLS and Ridge).\n",
    "\n",
    "Usage\n",
    "-----\n",
    ">>> from src.models.linear import fit_ridge\n",
    ">>> fitted, rmse = fit_ridge(train_df, val_df)\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def _split_xy(df: pd.DataFrame):\n",
    "    X = df.drop(columns=[\"exit_velo\"])\n",
    "    y = df[\"exit_velo\"]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def fit_ridge(X_tr: pd.DataFrame,\n",
    "              y_tr: pd.DataFrame,\n",
    "              X_te: pd.DataFrame,\n",
    "              y_te: pd.DataFrame,\n",
    "              alpha: float = 1.0):\n",
    "    \"\"\"\n",
    "    Returns (sklearn Pipeline, RMSE on test set).\n",
    "    \"\"\"\n",
    "\n",
    "    model = Pipeline(\n",
    "        [(\"reg\" , Ridge(alpha=alpha, random_state=0))]\n",
    "    ).fit(X_tr, y_tr)\n",
    "\n",
    "    pred = model.predict(X_te)\n",
    "    rmse = np.sqrt(np.mean((pred - y_te) ** 2))\n",
    "    return model, rmse\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    from src.data.load_data import load_raw\n",
    "    from src.features.feature_engineering import feature_engineer\n",
    "    from src.data.ColumnSchema import _ColumnSchema\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from src.features.preprocess import summarize_categorical_missingness\n",
    "    from src.features.preprocess import fit_preprocessor, transform_preprocessor, inverse_transform_preprocessor\n",
    "    raw_path = \"data/Research Data Project/Research Data Project/exit_velo_project_data.csv\"\n",
    "    df = load_raw(raw_path)\n",
    "    print(df.head())\n",
    "    print(df.columns)\n",
    "\n",
    "    # --- inspect nulls in the raw data ---\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    if null_counts.empty:\n",
    "        print(\"✅  No missing values in raw data.\")\n",
    "    else:\n",
    "        print(\"=== Raw data null counts ===\")\n",
    "        for col, cnt in null_counts.items():\n",
    "            print(f\" • {col!r}: {cnt} missing\")\n",
    "    df_fe = feature_engineer(df)\n",
    "\n",
    "    print(\"Raw →\", df.shape, \"//  Feature‑engineered →\", df_fe.shape)\n",
    "    print(df_fe.head())\n",
    "\n",
    "    # singleton instance people can import as `cols`\n",
    "    cols = _ColumnSchema()\n",
    "\n",
    "    __all__ = [\"cols\"]\n",
    "    print(\"ID columns:         \", cols.id())\n",
    "    print(\"Ordinal columns:    \", cols.ordinal())\n",
    "    print(\"Nominal columns:    \", cols.nominal())\n",
    "    print(\"All categorical:    \", cols.categorical())\n",
    "    print(\"Numerical columns:  \", cols.numerical())\n",
    "    print(\"Model features:     \", cols.model_features())\n",
    "    print(\"Target columns:  \", cols.target())\n",
    "    print(\"All raw columns:    \", cols.all_raw())\n",
    "    numericals = cols.numerical()\n",
    "    # use list‐comprehension to drop target(s) from numerical features\n",
    "    numericals_without_y = [c for c in numericals if c not in cols.target()]\n",
    "\n",
    "    summary_df = summarize_categorical_missingness(df_fe)\n",
    "    print(summary_df.to_markdown(index=False))\n",
    "\n",
    "\n",
    "    # check nulls\n",
    "    print(\"🛠️  Nulls in X before fit_transform:\")\n",
    "    null_counts = df_fe.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    if null_counts.empty:\n",
    "        print(\"✅  No missing values after feature engineering.\")\n",
    "    else:\n",
    "        print(\"=== Null counts post-engineering ===\")\n",
    "        print(null_counts)\n",
    "\n",
    "    train_df, test_df = train_test_split(df_fe, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "    # run with debug prints\n",
    "    X_train, y_train, tf = fit_preprocessor(train_df, model_type='linear', debug=True)\n",
    "    X_test,  y_test      = transform_preprocessor(test_df, tf)\n",
    "\n",
    "        \n",
    "    print(\"Processed shapes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "    # Example of inverse transform: \n",
    "    print(\"==========Example of inverse transform:==========\")\n",
    "    df_back = inverse_transform_preprocessor(X_train, tf)\n",
    "    print(\"\\n✅ Inverse‐transformed head (should mirror your original X_train):\")\n",
    "    print(df_back.head())\n",
    "    print(\"Shape:\", df_back.shape, \"→ original X_train shape before transform:\", X_train.shape)\n",
    "    \n",
    "\n",
    "    # === NEW: Train & evaluate Ridge regression ===\n",
    "    model_ridge, rmse_ridge = fit_ridge(X_train, y_train, X_test,  y_test)\n",
    "    print(f\"Ridge regression RMSE: {rmse_ridge:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season level_abbr  batter_id  pitcher_id  exit_velo  launch_angle  \\\n",
      "0    2023        mlb        235        1335    95.7352       47.2362   \n",
      "1    2023        mlb       3182        1335    95.9380        4.7291   \n",
      "2    2023        mlb       3856        1988    89.1404      -16.2251   \n",
      "3    2023        mlb       2017        1988    88.7278       -6.8385   \n",
      "4    2023        mlb       1594        1988    89.2888        0.5079   \n",
      "\n",
      "   spray_angle  hangtime     hit_type batter_hand pitcher_hand  batter_height  \\\n",
      "0      -6.4422    6.4960     fly_ball           R            R             72   \n",
      "1      -4.8052    0.7806  ground_ball           L            R             75   \n",
      "2      15.2382    0.0311  ground_ball           S            R             72   \n",
      "3     -11.5988    0.1215  ground_ball           R            R             69   \n",
      "4     -22.1899    0.3802  ground_ball           R            R             73   \n",
      "\n",
      "  pitch_group outcome   age  \n",
      "0          FB     out  32.8  \n",
      "1          OS     out  29.2  \n",
      "2          OS     out  29.7  \n",
      "3          BB     out  23.4  \n",
      "4          FB     out  35.3  \n",
      "Index(['season', 'level_abbr', 'batter_id', 'pitcher_id', 'exit_velo',\n",
      "       'launch_angle', 'spray_angle', 'hangtime', 'hit_type', 'batter_hand',\n",
      "       'pitcher_hand', 'batter_height', 'pitch_group', 'outcome', 'age'],\n",
      "      dtype='object')\n",
      "=== Raw data null counts ===\n",
      " • 'exit_velo': 97979 missing\n",
      " • 'launch_angle': 9130 missing\n",
      " • 'spray_angle': 6227 missing\n",
      " • 'hangtime': 75968 missing\n",
      " • 'hit_type': 201 missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\src\\features\\feature_engineering.py:133: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"pitcher_ev_mean50\"].fillna(df[\"exit_velo\"].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw → (1344651, 15) //  Feature‑engineered → (1344651, 33)\n",
      "   season level_abbr  batter_id  pitcher_id  exit_velo  launch_angle  \\\n",
      "0    2023        MLB        235        1335    95.7352       47.2362   \n",
      "1    2023        MLB       3182        1335    95.9380        4.7291   \n",
      "2    2023        MLB       3856        1988    89.1404      -16.2251   \n",
      "3    2023        MLB       2017        1988    88.7278       -6.8385   \n",
      "4    2023        MLB       1594        1988    89.2888        0.5079   \n",
      "\n",
      "   spray_angle  hangtime     hit_type batter_hand  ... pitch_hand_match  \\\n",
      "0      -6.4422    6.4960     FLY_BALL           R  ...        FB_R_VS_R   \n",
      "1      -4.8052    0.7806  GROUND_BALL           L  ...        OS_L_VS_R   \n",
      "2      15.2382    0.0311  GROUND_BALL           S  ...        OS_S_VS_R   \n",
      "3     -11.5988    0.1215  GROUND_BALL           R  ...        BB_R_VS_R   \n",
      "4     -22.1899    0.3802  GROUND_BALL           R  ...        FB_R_VS_R   \n",
      "\n",
      "   player_ev_mean50 player_ev_std50 hard_hit  near_barrel  ev_la_product  \\\n",
      "0         89.923631       12.088127     True        False   13138.335054   \n",
      "1         94.109155       13.340991     True        False    9088.120396   \n",
      "2         85.266690       13.363411    False        False    6576.324096   \n",
      "3         85.389481       16.746956    False        False    7378.736940   \n",
      "4         94.849458       12.962405    False        False    8081.341782   \n",
      "\n",
      "  est_distance  ev_la_sqrt pitcher_ev_mean50 outcome_val  \n",
      "0   621.895859  114.622577         85.828920         0.0  \n",
      "1    74.889203   95.331634         91.074314         0.0  \n",
      "2     2.772266   81.094538         92.208417         0.0  \n",
      "3    10.780428   85.899575         88.391978         0.0  \n",
      "4    33.947602   89.896283         92.155127         0.0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "ID columns:          ['season', 'batter_id', 'pitcher_id']\n",
      "Ordinal columns:     ['level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val']\n",
      "Nominal columns:     ['hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel']\n",
      "All categorical:     ['level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val', 'hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel']\n",
      "Numerical columns:   ['exit_velo', 'launch_angle', 'spray_angle', 'hangtime', 'ev_la_product', 'ev_la_sqrt', 'est_distance', 'player_ev_mean50', 'player_ev_std50', 'pitcher_ev_mean50']\n",
      "Model features:      ['launch_angle', 'spray_angle', 'hangtime', 'ev_la_product', 'ev_la_sqrt', 'est_distance', 'player_ev_mean50', 'player_ev_std50', 'pitcher_ev_mean50', 'hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel', 'level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val']\n",
      "Target columns:   exit_velo\n",
      "All raw columns:     ['season', 'batter_id', 'pitcher_id', 'level_abbr', 'age_bin', 'la_bin', 'spray_bin', 'outcome_val', 'hit_type', 'outcome', 'pitch_group', 'batter_hand', 'pitcher_hand', 'hand_match', 'pitch_hand_match', 'same_hand', 'is_barrel', 'hard_hit', 'near_barrel', 'exit_velo', 'launch_angle', 'spray_angle', 'hangtime', 'ev_la_product', 'ev_la_sqrt', 'est_distance', 'player_ev_mean50', 'player_ev_std50', 'pitcher_ev_mean50']\n",
      "| column           |   original_null_count |   original_null_pct |   imputed_missing_count |   imputed_missing_pct |\n",
      "|:-----------------|----------------------:|--------------------:|------------------------:|----------------------:|\n",
      "| level_abbr       |                     0 |         0           |                       0 |           0           |\n",
      "| age_bin          |                     0 |         0           |                       0 |           0           |\n",
      "| la_bin           |                  9130 |         0.00678987  |                    9130 |           0.00678987  |\n",
      "| spray_bin        |                  6227 |         0.00463094  |                    6227 |           0.00463094  |\n",
      "| outcome_val      |                 63271 |         0.0470538   |                   63271 |           0.0470538   |\n",
      "| hit_type         |                   201 |         0.000149481 |                     201 |           0.000149481 |\n",
      "| outcome          |                     0 |         0           |                       0 |           0           |\n",
      "| pitch_group      |                     0 |         0           |                       0 |           0           |\n",
      "| batter_hand      |                     0 |         0           |                       0 |           0           |\n",
      "| pitcher_hand     |                     0 |         0           |                       0 |           0           |\n",
      "| hand_match       |                     0 |         0           |                       0 |           0           |\n",
      "| pitch_hand_match |                     0 |         0           |                       0 |           0           |\n",
      "| same_hand        |                     0 |         0           |                       0 |           0           |\n",
      "| is_barrel        |                     0 |         0           |                       0 |           0           |\n",
      "| hard_hit         |                     0 |         0           |                       0 |           0           |\n",
      "| near_barrel      |                     0 |         0           |                       0 |           0           |\n",
      "🛠️  Nulls in X before fit_transform:\n",
      "=== Null counts post-engineering ===\n",
      "exit_velo         97979\n",
      "launch_angle       9130\n",
      "spray_angle        6227\n",
      "hangtime          75968\n",
      "hit_type            201\n",
      "la_bin             9130\n",
      "spray_bin          6227\n",
      "ev_la_product     97981\n",
      "est_distance     110411\n",
      "ev_la_sqrt        97981\n",
      "outcome_val       63271\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\src\\features\\preprocess.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[ord_feats] = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected ordinal categories: [('level_abbr', ['MLB', 'AAA', 'AA', 'MISSING']), ('age_bin', ['(26.3, 28.9]', '(24.5, 26.3]', '(28.9, 43.0]', '(17.099, 24.5]', 'MISSING']), ('la_bin', ['(-89.685, -10.533]', '(35.19, 89.875]', '(-10.533, 6.002]', '(19.631, 35.19]', '(6.002, 19.631]', 'MISSING']), ('spray_bin', ['(-179.916, -12.664]', '(-12.664, 9.63]', '(9.63, 179.962]', 'MISSING']), ('outcome_val', ['0.0', '1.0', '2.0', '3.0', 'MISSING'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\src\\features\\preprocess.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[ord_feats] = (\n",
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed shapes: (990200, 58) (249198, 58)\n",
      "==========Example of inverse transform:==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\docker_projects\\Marlins_Data_Science_Project\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 2, 3, 4, 5, 6] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Inverse‐transformed head (should mirror your original X_train):\n",
      "   launch_angle  spray_angle  hangtime  ev_la_product  ev_la_sqrt  \\\n",
      "0      -20.7923     -44.3123    0.1277    3261.025299   57.105388   \n",
      "1       44.5676       3.1201    6.0871   12641.549479  112.434645   \n",
      "2       49.3999     -32.1939    4.3439    8662.978906   93.075125   \n",
      "3        0.6769       5.6467    0.3372    9277.924393   96.321983   \n",
      "4       37.1261     -26.3477    5.5243   11487.305085  107.178846   \n",
      "\n",
      "   est_distance  player_ev_mean50  player_ev_std50  pitcher_ev_mean50  \\\n",
      "0      6.017147         89.726660        14.893938          91.562006   \n",
      "1    571.834348         89.320567        19.629693          90.466646   \n",
      "2    269.950797         84.978622        15.285691          85.517696   \n",
      "3     34.501798         87.332024        18.400426          88.802587   \n",
      "4    499.184034         97.734258        11.093887          89.354354   \n",
      "\n",
      "  level_abbr  ... outcome pitch_group batter_hand pitcher_hand hand_match  \\\n",
      "0        MLB  ...     OUT          FB           R            R     R_VS_R   \n",
      "1        MLB  ...     OUT          BB           L            L     L_VS_L   \n",
      "2        MLB  ...  SINGLE          OS           L            R     L_VS_R   \n",
      "3        AAA  ...     OUT          FB           R            L     R_VS_L   \n",
      "4        MLB  ...     OUT          FB           R            L     R_VS_L   \n",
      "\n",
      "  pitch_hand_match same_hand is_barrel hard_hit near_barrel  \n",
      "0        FB_R_VS_R      True     False    False       False  \n",
      "1        BB_L_VS_L      True     False    False       False  \n",
      "2        OS_L_VS_R     False     False    False       False  \n",
      "3        FB_R_VS_L     False     False     True       False  \n",
      "4        FB_R_VS_L     False     False    False       False  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "Shape: (990200, 25) → original X_train shape before transform: (990200, 58)\n",
      "XGBoost GBM model RMSE: 0.6656\n"
     ]
    }
   ],
   "source": [
    "# %%writefile src/models/gbm.py\n",
    "\n",
    "\"\"\"\n",
    "Gradient‑boosting baseline (XGBoost regressor).\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor                       # pip install xgboost\n",
    "\n",
    "\n",
    "def _split_xy(df: pd.DataFrame):\n",
    "    X = df.drop(columns=[\"exit_velo\"])\n",
    "    y = df[\"exit_velo\"]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def fit_gbm(X_tr: pd.DataFrame,\n",
    "            y_tr: pd.DataFrame,\n",
    "            X_te: pd.DataFrame,\n",
    "            y_te: pd.DataFrame,\n",
    "            **gbm_kw):\n",
    "    \"\"\"\n",
    "    Returns (sklearn Pipeline, RMSE).\n",
    "    \"\"\"\n",
    "    gbm_default = dict(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.6,\n",
    "        random_state=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    gbm_default.update(gbm_kw)\n",
    "\n",
    "    model = Pipeline(\n",
    "        [(\"gbm\" , XGBRegressor(**gbm_default))]\n",
    "    ).fit(X_tr, y_tr)\n",
    "\n",
    "    pred = model.predict(X_te)\n",
    "    rmse = np.sqrt(np.mean((pred - y_te) ** 2))\n",
    "    return model, rmse\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    from src.data.load_data import load_raw\n",
    "    from src.features.feature_engineering import feature_engineer\n",
    "    from src.data.ColumnSchema import _ColumnSchema\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from src.features.preprocess import summarize_categorical_missingness\n",
    "    from src.features.preprocess import fit_preprocessor, transform_preprocessor, inverse_transform_preprocessor\n",
    "    raw_path = \"data/Research Data Project/Research Data Project/exit_velo_project_data.csv\"\n",
    "    df = load_raw(raw_path)\n",
    "    print(df.head())\n",
    "    print(df.columns)\n",
    "\n",
    "    # --- inspect nulls in the raw data ---\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    if null_counts.empty:\n",
    "        print(\"✅  No missing values in raw data.\")\n",
    "    else:\n",
    "        print(\"=== Raw data null counts ===\")\n",
    "        for col, cnt in null_counts.items():\n",
    "            print(f\" • {col!r}: {cnt} missing\")\n",
    "    df_fe = feature_engineer(df)\n",
    "\n",
    "    print(\"Raw →\", df.shape, \"//  Feature‑engineered →\", df_fe.shape)\n",
    "    print(df_fe.head())\n",
    "\n",
    "    # singleton instance people can import as `cols`\n",
    "    cols = _ColumnSchema()\n",
    "\n",
    "    __all__ = [\"cols\"]\n",
    "    print(\"ID columns:         \", cols.id())\n",
    "    print(\"Ordinal columns:    \", cols.ordinal())\n",
    "    print(\"Nominal columns:    \", cols.nominal())\n",
    "    print(\"All categorical:    \", cols.categorical())\n",
    "    print(\"Numerical columns:  \", cols.numerical())\n",
    "    print(\"Model features:     \", cols.model_features())\n",
    "    print(\"Target columns:  \", cols.target())\n",
    "    print(\"All raw columns:    \", cols.all_raw())\n",
    "    numericals = cols.numerical()\n",
    "    # use list‐comprehension to drop target(s) from numerical features\n",
    "    numericals_without_y = [c for c in numericals if c not in cols.target()]\n",
    "\n",
    "    summary_df = summarize_categorical_missingness(df_fe)\n",
    "    print(summary_df.to_markdown(index=False))\n",
    "\n",
    "\n",
    "    # check nulls\n",
    "    print(\"🛠️  Nulls in X before fit_transform:\")\n",
    "    null_counts = df_fe.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    if null_counts.empty:\n",
    "        print(\"✅  No missing values after feature engineering.\")\n",
    "    else:\n",
    "        print(\"=== Null counts post-engineering ===\")\n",
    "        print(null_counts)\n",
    "\n",
    "    train_df, test_df = train_test_split(df_fe, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "    # run with debug prints\n",
    "    X_train, y_train, tf = fit_preprocessor(train_df, model_type='linear', debug=True)\n",
    "    X_test,  y_test      = transform_preprocessor(test_df, tf)\n",
    "\n",
    "        \n",
    "    print(\"Processed shapes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "    # Example of inverse transform: \n",
    "    print(\"==========Example of inverse transform:==========\")\n",
    "    df_back = inverse_transform_preprocessor(X_train, tf)\n",
    "    print(\"\\n✅ Inverse‐transformed head (should mirror your original X_train):\")\n",
    "    print(df_back.head())\n",
    "    print(\"Shape:\", df_back.shape, \"→ original X_train shape before transform:\", X_train.shape)\n",
    "    \n",
    "\n",
    "\n",
    "    # === Train & evaluate mixed‐effects model ===\n",
    "    gbm_model, rmse_gbm = fit_gbm(X_train, y_train, X_test,  y_test)\n",
    "    print(f\"XGBoost GBM model RMSE: {rmse_gbm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\docker_projects\\Marlins_Data_Science_Project\\src\\features\\feature_engineering.py:133: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"pitcher_ev_mean50\"].fillna(df[\"exit_velo\"].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed-effects model RMSE: 13.8272\n"
     ]
    }
   ],
   "source": [
    "# %%writefile src/models/mixed.py\n",
    "\n",
    "\"\"\"\n",
    "Frequentist mixed‑effects model using statsmodels MixedLM.\n",
    "\n",
    "Formula implemented:\n",
    "    exit_velo ~ 1 + level_ord + age_centered\n",
    "              + (1 | batter_id)\n",
    "\n",
    "We rely on columns already produced by preprocess():\n",
    "    • level_idx  (0,1,2)   – ordinal\n",
    "    • age_centered\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "def fit_mixed(train: pd.DataFrame,\n",
    "              test: pd.DataFrame):\n",
    "    \"\"\"Return (fitted model, RMSE on test).\"\"\"\n",
    "    # statsmodels wants a *single* DataFrame with all cols\n",
    "    # so we concatenates and keep row positions for slicing\n",
    "    combined = pd.concat([train, test], axis=0)\n",
    "    # ensure categorical dtype\n",
    "    combined[\"level_ord\"] = combined[\"level_idx\"].astype(int)\n",
    "\n",
    "    mdl = smf.mixedlm(\n",
    "        formula=\"exit_velo ~ 1 + level_ord + age_centered\",\n",
    "        data=combined.iloc[: len(train)],\n",
    "        groups=combined.iloc[: len(train)][\"batter_id\"]\n",
    "    ).fit(reml=False)\n",
    "\n",
    "    # predict on test set\n",
    "    pred = mdl.predict(exog=combined.iloc[len(train):])\n",
    "    true = test[\"exit_velo\"].values\n",
    "    rmse = np.sqrt(np.mean((pred - true) ** 2))\n",
    "    return mdl, rmse\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from src.data.load_data import load_raw\n",
    "    from src.features.feature_engineering import feature_engineer\n",
    "    from src.features.preprocess import prepare_for_mixed_and_hierarchical\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    raw_path = \"data/Research Data Project/Research Data Project/exit_velo_project_data.csv\"\n",
    "    df = load_raw(raw_path)\n",
    "    df_fe = feature_engineer(df)\n",
    "\n",
    "    # Prepare and split\n",
    "    df_model = prepare_for_mixed_and_hierarchical(df_fe)\n",
    "    train_df, test_df = train_test_split(df_model, test_size=0.2, random_state=42)\n",
    " \n",
    "    # Fit mixed-effects\n",
    "    mixed_model, rmse_mixed = fit_mixed(train_df, test_df)\n",
    "    print(f\"Mixed-effects model RMSE: {rmse_mixed:.4f}\")\n",
    "\n",
    "    # In the smoke test section: P-Value Checks for Mixed-Effects Models\n",
    "    print(\"Mixed-effects model summary:\\n\", mixed_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/utils/bayesian_explainability.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils/bayesian_explainability.py\n",
    "import arviz as az\n",
    "import shap, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- Posterior summaries -----------------\n",
    "def plot_parameter_forest(idata, var_names=None, hdi_prob=0.95):\n",
    "    \"\"\"Caterpillar/forest plot of posterior estimates.\"\"\"\n",
    "    return az.plot_forest(\n",
    "        idata,\n",
    "        var_names=var_names,\n",
    "        combined=True,\n",
    "        hdi_prob=hdi_prob,\n",
    "        kind=\"forest\",\n",
    "        figsize=(6, len(var_names or idata.posterior.data_vars) * 0.4),\n",
    "    )\n",
    "\n",
    "def posterior_table(idata, round_to=2):\n",
    "    \"\"\"\n",
    "    Return a nicely rounded HDI/mean table with significance.\n",
    "    \"\"\"\n",
    "    summary = az.summary(idata, hdi_prob=0.95).round(round_to)\n",
    "    summary[\"significant\"] = (summary[\"hdi_2.5%\"] > 0) | (summary[\"hdi_97.5%\"] < 0)\n",
    "    return summary\n",
    "\n",
    "# ---------------- Posterior‑predictive checks ---------\n",
    "def plot_ppc(idata, kind=\"overlay\"):\n",
    "    \"\"\"Visual PPC (over‑laid densities by default).\"\"\"\n",
    "    return az.plot_ppc(idata, kind=kind, alpha=0.1)\n",
    "\n",
    "# ---------------- SHAP-based feature importances ------\n",
    "def shap_explain(predict_fn, background_df, sample_df):\n",
    "    \"\"\"\n",
    "    Model‑agnostic Kernel SHAP on the *posterior mean predictor*.\n",
    "\n",
    "    predict_fn(df) must return a 1‑D numpy array of predictions.\n",
    "    \"\"\"\n",
    "    explainer = shap.KernelExplainer(predict_fn, background_df)\n",
    "    shap_values = explainer.shap_values(sample_df, nsamples=200)\n",
    "    shap.summary_plot(shap_values, sample_df, show=False)\n",
    "    plt.tight_layout()\n",
    "    return shap_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/models/hierarchical.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/models/hierarchical.py\n",
    "\n",
    "import jax\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "# Configure JAX for GPU use and X64 precision\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "print(\"JAX version:\", jax.__version__)\n",
    "print(\"JAX devices:\", jax.devices())\n",
    "print(\"GPU count:\", jax.device_count(\"gpu\"))\n",
    "print(\"Default backend:\", jax.default_backend())\n",
    "\n",
    "import logging, pymc.sampling.jax as pmjax\n",
    "\n",
    "\n",
    "# ── NEW: fit_bayesian_hierarchical with timing & ETAs ────────────────\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from tqdm.auto import tqdm          # auto‑selects rich bar in Jupyter / CLI\n",
    "\n",
    "@contextmanager\n",
    "def _timed_section(label: str):\n",
    "    \"\"\"Context manager that prints elapsed time for a code block.\"\"\"\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[{label}] finished in {dt:,.1f} s\")\n",
    "\n",
    "def fit_bayesian_hierarchical(\n",
    "    df,\n",
    "    batter_idx: np.ndarray,\n",
    "    level_idx: np.ndarray,\n",
    "    age_centered: np.ndarray,\n",
    "    mu_prior: float,\n",
    "    sigma_prior: float,\n",
    "    *,\n",
    "    use_ar1: bool = False,\n",
    "    sampler: str = \"nuts\",          # \"nuts\", \"nutpie\", or \"advi\"\n",
    "    draws: int = 1000,\n",
    "    tune: int = 1000,\n",
    "    advi_iters: int = 50_000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Hierarchical Exit‑Velocity model with rich progress bars & ETAs.\n",
    "    Returns a single ArviZ InferenceData object (posterior ⊕ PPC).\n",
    "    \"\"\"\n",
    "    y      = df[\"exit_velo\"].values\n",
    "    n_bat  = df[\"batter_id\"].nunique()\n",
    "    n_lvl  = df[\"level_idx\"].nunique()\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # ─── Priors ────────────────────────────────────────────────\n",
    "        mu         = pm.Normal(\"mu\", mu_prior, sigma_prior)\n",
    "        beta_level = pm.Normal(\"beta_level\", 0.0, 5.0, shape=n_lvl)\n",
    "        beta_age   = pm.Normal(\"beta_age\",   0.0, 1.0)\n",
    "        sigma_b    = pm.HalfNormal(\"sigma_b\", sigma_prior)\n",
    "        sigma_e    = pm.HalfNormal(\"sigma_e\", sigma_prior / 2)\n",
    "\n",
    "        u = (\n",
    "            pm.GaussianRandomWalk(\"u\", sigma=sigma_b, shape=n_bat)\n",
    "            if use_ar1 else\n",
    "            pm.Normal(\"u\", mu=0.0, sigma=sigma_b, shape=n_bat)\n",
    "        )\n",
    "\n",
    "        theta = (\n",
    "            mu\n",
    "            + beta_level[level_idx]\n",
    "            + beta_age * age_centered\n",
    "            + u[batter_idx]\n",
    "        )\n",
    "        pm.Normal(\"y_obs\", mu=theta, sigma=sigma_e, observed=y)\n",
    "\n",
    "        # ─── Inference ─────────────────────────────────────────────\n",
    "        if sampler == \"advi\":\n",
    "            print(f\"Running ADVI ({advi_iters:,} iters) …\")\n",
    "            with _timed_section(\"ADVI\"):\n",
    "                approx = pm.fit(\n",
    "                    n=advi_iters,\n",
    "                    method=\"advi\",\n",
    "                    progressbar=True,\n",
    "                )                    # PyMC shows a tqdm bar internally\n",
    "            with _timed_section(\"Sampling from ADVI guide\"):\n",
    "                idata = approx.sample(draws=draws, progressbar=True)\n",
    "\n",
    "        else:                        # HMC family\n",
    "            total_steps = (draws + tune)\n",
    "            print(f\"Running {sampler.upper()} : {draws:,} draws + \"\n",
    "                  f\"{tune:,} tune per chain (4 chains → {total_steps*4:,} steps)\")\n",
    "            sample_kwargs = dict(\n",
    "                draws=draws, tune=tune, chains=4,\n",
    "                target_accept=0.9, return_inferencedata=True,\n",
    "                progressbar=True                      # PyMC uses tqdm\n",
    "            )\n",
    "            # select sampler backend\n",
    "            if sampler == \"nutpie\":\n",
    "                sample_kwargs[\"nuts_sampler\"] = \"nutpie\"\n",
    "            elif sampler == \"jax\":\n",
    "                # Use JAX backend with GPU\n",
    "                print(\"Using JAX on GPU for sampling\")\n",
    "                sample_kwargs[\"nuts_sampler\"] = \"numpyro\"\n",
    "                if jax.device_count(\"gpu\") > 0:\n",
    "                    print(\"GPU is available for sampling\")\n",
    "                else:\n",
    "                    print(\"Warning: No GPU detected, using CPU instead\")\n",
    "\n",
    "            # Attempt JAX HMC, catch XLA dtype bug and fallback to nutpie\n",
    "            with _timed_section(\"HMC sampling\"):\n",
    "                try:\n",
    "                    idata = pm.sample(**sample_kwargs)\n",
    "                except Exception as e:\n",
    "                    # detect JAX XLARuntimeError by message or type\n",
    "                    if \"CpuCallback error\" in str(e) or \"Incorrect output dtype\" in str(e):\n",
    "                        print(\"⚠️  JAX sampler failed due to dtype bug; falling back to nutpie sampler\")\n",
    "                        sample_kwargs[\"nuts_sampler\"] = \"nutpie\"\n",
    "                        idata = pm.sample(**sample_kwargs)\n",
    "                    else:\n",
    "                        print(f\"Error during sampling: {e}\")\n",
    "                        raise\n",
    "\n",
    "        # ─── Posterior predictive ─────────────────────────────────\n",
    "        n_ppc = y.size * draws\n",
    "        print(f\"Generating PPC ({draws:,} draws → {n_ppc:,} values) …\")\n",
    "        with _timed_section(\"Posterior predictive\"):\n",
    "            ppc = pm.sample_posterior_predictive(\n",
    "                idata, var_names=[\"y_obs\"], progressbar=True\n",
    "            )\n",
    "\n",
    "    return az.concat(idata, ppc)\n",
    "\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "# 6. Smoke test (only run when module executed directly)\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    from src.data.load_data import load_raw\n",
    "    from src.features.feature_engineering import feature_engineer\n",
    "    from src.features.preprocess import prepare_for_mixed_and_hierarchical\n",
    "\n",
    "\n",
    "    raw_path = \"data/Research Data Project/Research Data Project/exit_velo_project_data.csv\"\n",
    "    df = load_raw(raw_path)\n",
    "    df_fe = feature_engineer(df)\n",
    "\n",
    "    # Prepare the DataFrame\n",
    "    df_model = prepare_for_mixed_and_hierarchical(df_fe)\n",
    "\n",
    "    # Extract arrays for PyMC\n",
    "    batter_idx = df_model[\"batter_id\"].cat.codes.values\n",
    "    level_idx = df_model[\"level_idx\"].values\n",
    "    age_centered = df_model[\"age_centered\"].values\n",
    "\n",
    "    # Fit the Bayesian hierarchical model\n",
    "    idata = fit_bayesian_hierarchical(\n",
    "        df_model, batter_idx, level_idx, age_centered,\n",
    "        mu_prior=90, sigma_prior=5,\n",
    "        sampler=\"jax\",   #  <-- GPU NUTS\n",
    "        draws=1000, tune=1000\n",
    "    )\n",
    "\n",
    "    print(idata)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/models/hierarchical_predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/models/hierarchical_predict.py\n",
    "from src.utils.bayesian_explainability import (\n",
    "    plot_parameter_forest, posterior_table, plot_ppc, shap_explain\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ ==\n",
    "    # --- NEW: helper for SHAP ---------------------------------\n",
    "    posterior_mean = idata.posterior.mean(dim=(\"chain\", \"draw\"))\n",
    "    coef_level = posterior_mean[\"beta_level\"].values\n",
    "    coef_age = posterior_mean[\"beta_age\"].values\n",
    "    mu_hat = posterior_mean[\"mu\"].values\n",
    "\n",
    "    def predict(df):\n",
    "        return (\n",
    "            mu_hat\n",
    "            + coef_level[df[\"level_idx\"].values]\n",
    "            + coef_age * df[\"age_centered\"].values\n",
    "        )\n",
    "\n",
    "    pmjax._numpyro_stats_to_dict.__globals__[\"np\"].log2 = _debug_log2\n",
    "    \n",
    "    # 1️⃣  Convergence / coefficient credibility\n",
    "    plot_parameter_forest(idata, var_names=[\"beta_level\", \"beta_age\"])\n",
    "    \n",
    "    # After fitting Bayesian model:\n",
    "    summary = posterior_table(idata)\n",
    "    print(\"Posterior Table with Significance:\\n\", summary)\n",
    "    # 2️⃣  Posterior‑predictive overlay\n",
    "    plot_ppc(idata)\n",
    "\n",
    "    # 3️⃣  WAIC & LOO (single‐line outputs)\n",
    "    print(\"WAIC:\", az.waic(idata).waic, \"  LOO:\", az.loo(idata).loo)\n",
    "\n",
    "    # 4️⃣  Global & local feature importance\n",
    "    shap_explain(\n",
    "        predict_fn=predict,\n",
    "        background_df=df_model.sample(200, random_state=0),\n",
    "        sample_df=df_model.sample(200, random_state=1),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/utils/validation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils/validation.py\n",
    "\"\"\"\n",
    "Generic K‑fold validator.\n",
    "\n",
    "• Works for sklearn Pipelines *or* PyMC idata.\n",
    "• Decides how to extract predictions based on\n",
    "  the object returned by `fit_func`.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import arviz as az\n",
    "\n",
    "from __future__ import annotations\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from typing import Callable, List, Union\n",
    "import statsmodels as sm\n",
    "\n",
    "def _split_xy(df: pd.DataFrame):\n",
    "    X = df.drop(columns=[\"exit_velo\"])\n",
    "    y = df[\"exit_velo\"]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def _rmse(a, b):\n",
    "    return np.sqrt(np.mean((a - b) ** 2))\n",
    "\n",
    "\n",
    "def run_kfold_cv(\n",
    "    fit_func: Callable[[pd.DataFrame, pd.DataFrame], tuple],\n",
    "    df: pd.DataFrame,\n",
    "    k: int = 5,\n",
    "    random_state: int = 0,\n",
    "    **fit_kw\n",
    ") -> List[float]:\n",
    "    \"\"\"\n",
    "    fit_func(train_df, test_df, **fit_kw) -> (model_or_idata, rmse)\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    rmses: List[float] = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(df):\n",
    "        train, test = df.iloc[train_idx], df.iloc[test_idx]\n",
    "        _, rmse = fit_func(train, test, **fit_kw)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return rmses\n",
    "\n",
    "\n",
    "# helper to score a *single* train/test split for idata\n",
    "def rmse_pymc(idata: az.InferenceData, test_df: pd.DataFrame) -> float:\n",
    "    \"\"\"Posterior mean vs truth.\"\"\"\n",
    "    pred = (\n",
    "        idata.posterior_predictive[\"y_obs\"]\n",
    "        .mean((\"chain\", \"draw\"))\n",
    "        .values\n",
    "    )\n",
    "    return _rmse(pred, test_df[\"exit_velo\"].values)\n",
    "\n",
    "def run_kfold_cv(fit_func, df, k=5, random_state=0, **fit_kwargs):\n",
    "    \"\"\"\n",
    "    Apply `fit_func(train_df, **fit_kwargs)` then evaluate on held-out.\n",
    "    Returns list of held-out log_likelihoods or RMSEs.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    scores = []\n",
    "    for train_idx, test_idx in kf.split(df):\n",
    "        train, test = df.iloc[train_idx], df.iloc[test_idx]\n",
    "        idata = fit_func(train, **fit_kwargs)\n",
    "\n",
    "        # posterior predictive on test\n",
    "        ppc = az.from_pymc(posterior_predictive=idata, model=None)\n",
    "        pred_mean = ppc.posterior_predictive[\"y_obs\"].mean((\"chain\",\"draw\")).values\n",
    "        true = test[\"exit_velo\"].values\n",
    "        rmse = np.sqrt(((pred_mean - true)**2).mean())\n",
    "        scores.append(rmse)\n",
    "    return scores\n",
    "\n",
    "def posterior_predictive_check(idata, df, batter_idx):\n",
    "    \"\"\"\n",
    "    Plot observed vs. simulated exit-velo histograms.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    obs = df[\"exit_velo\"].values\n",
    "    sim = idata.posterior_predictive[\"y_obs\"].stack(samples=(\"chain\",\"draw\")).values.flatten()\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(8,3))\n",
    "    ax[0].hist(obs, bins=30); ax[0].set_title(\"Observed\")\n",
    "    ax[1].hist(sim, bins=30); ax[1].set_title(\"Simulated\")\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prediction_interval(model, X, alpha=0.05, method='linear'):\n",
    "    \"\"\"\n",
    "    Compute prediction intervals for a model.\n",
    "    \"\"\"\n",
    "    if method == 'linear':\n",
    "        # For OLS and Ridge\n",
    "        X_const = sm.add_constant(X)\n",
    "        preds = model.get_prediction(X_const)\n",
    "        pred_int = preds.conf_int(alpha=alpha)\n",
    "        return preds.predicted_mean, pred_int[:, 0], pred_int[:, 1]\n",
    "    elif method == 'bayesian':\n",
    "        # For Bayesian models\n",
    "        hdi = az.hdi(model, hdi=1 - alpha)\n",
    "        return (\n",
    "            hdi.posterior_predictive.y_obs.sel(hdi=f\"{alpha/2*100}%\"),\n",
    "            hdi.posterior_predictive.y_obs.sel(hdi=f\"{(1-alpha/2)*100}%\")\n",
    "        )\n",
    "    elif method == 'gbm':\n",
    "        # For XGBoost quantile regression\n",
    "        lower = model.predict(X, pred_contribs=False, iteration_range=(0, model.best_iteration))\n",
    "        upper = model.predict(X, pred_contribs=False, iteration_range=(0, model.best_iteration))\n",
    "        return lower, upper  # Replace with actual quantile regression\n",
    "    else:\n",
    "        raise ValueError(\"Method not supported\")\n",
    "\n",
    "# Example for bootstrapping GBM\n",
    "def bootstrap_prediction_interval(model, X, n_bootstraps=1000, alpha=0.05):\n",
    "    preds = np.zeros((n_bootstraps, X.shape[0]))\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = np.random.choice(X.shape[0], X.shape[0], replace=True)\n",
    "        preds[i] = model.predict(X[indices])\n",
    "    lower = np.percentile(preds, 100 * alpha / 2, axis=0)\n",
    "    upper = np.percentile(preds, 100 * (1 - alpha / 2), axis=0)\n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "# 6. Smoke test (only run when module executed directly)\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    from src.data.load_data import load_raw\n",
    "    from src.features.feature_engineering import feature_engineer\n",
    "    from src.features.preprocess import prepare_for_mixed_and_hierarchical\n",
    "\n",
    "    raw_path = \"data/Research Data Project/Research Data Project/exit_velo_project_data.csv\"\n",
    "    df = load_raw(raw_path)\n",
    "    df_fe = feature_engineer(df)\n",
    "\n",
    "    # Prepare the DataFrame\n",
    "    df_model = prepare_for_mixed_and_hierarchical(df_fe)\n",
    "\n",
    "    # Extract arrays for PyMC\n",
    "    batter_idx   = df_model[\"batter_id\"].cat.codes.values\n",
    "    level_idx    = df_model[\"level_idx\"].values\n",
    "    age_centered = df_model[\"age_centered\"].values\n",
    "\n",
    "    # Fit the Bayesian hierarchical model\n",
    "    idata = fit_bayesian_hierarchical(\n",
    "        df_model, batter_idx, level_idx, age_centered,\n",
    "        mu_prior=90, sigma_prior=5,\n",
    "        sampler=\"jax\",   #  <-- GPU NUTS\n",
    "        draws=1000, tune=1000\n",
    "    )\n",
    "\n",
    "    print(idata)\n",
    "    \n",
    "    posterior_predictive_check(idata, df_model, df_model.batter_id.cat.codes.values)\n",
    "    \n",
    "    # For Bayesian model:\n",
    "    lower, upper = prediction_interval(idata, test_df, method='bayesian')\n",
    "    print(f\"Bayesian 95% Prediction Interval: {lower.mean():.2f}–{upper.mean():.2f} mph\")\n",
    "\n",
    "    # For Ridge model:\n",
    "    pred, lower, upper = prediction_interval(model_ridge, X_test, method='linear')\n",
    "    print(f\"Ridge 95% Prediction Interval: {lower[0]:.2f}–{upper[0]:.2f} mph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/train.py\n",
    "\"\"\"\n",
    "Train / compare four families on a 70‑30 split.\n",
    "\n",
    "Run:\n",
    "    python -m src.train\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.data.load_data import load_raw\n",
    "from src.features.preprocess import preprocess\n",
    "\n",
    "from src.models.linear import fit_ridge\n",
    "from src.models.gbm   import fit_gbm\n",
    "from src.models.mixed import fit_mixed\n",
    "from src.models.hierarchical import fit_bayesian_hierarchical\n",
    "\n",
    "RAW_PATH = \"data/Research Data Project/Research Data Project/exit_velo_project_data.csv\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    df_raw   = load_raw(RAW_PATH)\n",
    "    df_clean = preprocess(df_raw)\n",
    "\n",
    "    train_df, test_df = train_test_split(\n",
    "        df_clean, test_size=0.30, random_state=42, stratify=df_clean[\"level_abbr\"]\n",
    "    )\n",
    "\n",
    "    # ––– A  Ridge  –––––––––––––––––––––––––––––––\n",
    "    _, rmse_ridge = fit_ridge(train_df, test_df)\n",
    "    print(f\"Ridge RMSE ……  {rmse_ridge:5.2f} mph\")\n",
    "\n",
    "    # ––– B  Gradient‑Boost  ––––––––––––––––––––––\n",
    "    _, rmse_gbm = fit_gbm(train_df, test_df)\n",
    "    print(f\"XGBoost RMSE … {rmse_gbm:5.2f} mph\")\n",
    "\n",
    "    # ––– C  Mixed‑Effects  –––––––––––––––––––––––\n",
    "    _, rmse_mixed = fit_mixed(train_df, test_df)\n",
    "    print(f\"Mixed‑LM RMSE  {rmse_mixed:5.2f} mph\")\n",
    "\n",
    "    # ––– D  Bayesian Hierarchical (quick sample) –\n",
    "    idata = fit_bayesian_hierarchical(\n",
    "        train_df,\n",
    "        batter_idx=train_df.batter_id.astype(\"category\").cat.codes.values,\n",
    "        level_idx=train_df.level_idx.values,\n",
    "        age_centered=train_df.age_centered.values,\n",
    "        mu_prior=90,\n",
    "        sigma_prior=5,\n",
    "        draws=500, tune=500   # short run for demo\n",
    "    )\n",
    "    from src.utils.validation import rmse_pymc\n",
    "    rmse_bayes = rmse_pymc(idata, test_df)\n",
    "    print(f\"PyMC RMSE ……  {rmse_bayes:5.2f} mph\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile src/models/model_shap_reports.py\n",
    "# ── NEW: shapash and shapiq imports\n",
    "from shapash import SmartExplainer\n",
    "import shapiq\n",
    "\n",
    "def generate_shapash_report(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    features_dict: dict | None = None,\n",
    "    preprocessing: object | None = None,\n",
    "    report_path: str = \"shapash_report.html\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Instantiate Shapash SmartExplainer, compile with data, and\n",
    "    generate both a live app and a standalone HTML report.\n",
    "\n",
    "    Parameters:\n",
    "    - model: trained ML model (supports .predict)\n",
    "    - X: pd.DataFrame, input features\n",
    "    - y: pd.Series or array, true target values\n",
    "    - features_dict: optional mapping {col: label} for display\n",
    "    - preprocessing: optional transformer with inverse_transform\n",
    "    - report_path: file path to save HTML report\n",
    "    \"\"\"\n",
    "    # 1️⃣ Create the explainer\n",
    "    xpl = SmartExplainer(\n",
    "        model=model,\n",
    "        features_dict=features_dict or {c: c for c in X.columns},\n",
    "        preprocessing=preprocessing\n",
    "    )\n",
    "    # 2️⃣ Compile dataset for Shapash\n",
    "    y_pred = model.predict(X)\n",
    "    xpl.compile(\n",
    "        x=X,\n",
    "        y_pred=y_pred,\n",
    "        y_target=y,\n",
    "        additional_data=None\n",
    "    )\n",
    "    # 3️⃣ Launch interactive app (optional; returns a Flask app)\n",
    "    # app = xpl.run_app()\n",
    "    # 4️⃣ Generate standalone HTML report\n",
    "    xpl.generate_report(\n",
    "        output_file=report_path,\n",
    "        title_story=\"Model Explainability Report\",\n",
    "        title_description=\"Auto-generated by Shapash\",\n",
    "        x_train=None, y_train=None, y_test=X, metrics=[]\n",
    "    )\n",
    "    # Return the explainer for further interaction\n",
    "    return xpl\n",
    "\n",
    "def compute_shapiq_interactions(\n",
    "    model,\n",
    "    X,\n",
    "    sample_size: int = 100,\n",
    "    max_order: int = 2\n",
    "):\n",
    "    \"\"\"\n",
    "    Use shapiq to compute Shapley Interaction values up to `max_order`\n",
    "    for up to `sample_size` observations.\n",
    "\n",
    "    Parameters:\n",
    "    - model: trained ML model\n",
    "    - X: pd.DataFrame of features\n",
    "    - sample_size: how many rows to explain\n",
    "    - max_order: maximum interaction order (e.g., 2 for pairwise)\n",
    "    \n",
    "    Returns:\n",
    "    - interaction_values: shapiq InteractionValues object\n",
    "    \"\"\"\n",
    "    # 1️⃣ Sample data for performance\n",
    "    X_sample = X.sample(n=min(len(X), sample_size), random_state=42).to_numpy()\n",
    "    # 2️⃣ Instantiate the explainer\n",
    "    explainer = shapiq.TabularExplainer(\n",
    "        model=model,\n",
    "        data=X_sample,\n",
    "        index=\"k-SII\",   # or \"SV\" for standard Shapley values\n",
    "        max_order=max_order\n",
    "    )\n",
    "    # 3️⃣ Explain the first sample\n",
    "    interaction_values = explainer.explain(X_sample[0], budget=256)\n",
    "    return interaction_values\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
